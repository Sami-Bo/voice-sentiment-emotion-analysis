{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afe455d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sr No.                                          Utterance   Speaker  \\\n",
      "0       1     Oh my God, hes lost it. Hes totally lost it.    Phoebe   \n",
      "1       2                                              What?    Monica   \n",
      "2       3  Or! Or, we could go to the bank, close our acc...      Ross   \n",
      "3       4                                   Youre a genius!  Chandler   \n",
      "4       5            Aww, man, now we wont be bank buddies!      Joey   \n",
      "\n",
      "    Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode StartTime  \\\n",
      "0   sadness  negative            0             0       4        7   20:57,3   \n",
      "1  surprise  negative            0             1       4        7   21:01,9   \n",
      "2   neutral   neutral            1             0       4        4   12:24,7   \n",
      "3       joy  positive            1             1       4        4   12:32,3   \n",
      "4   sadness  negative            1             2       4        4   12:34,2   \n",
      "\n",
      "   EndTime  \n",
      "0  21:00,0  \n",
      "1  21:03,3  \n",
      "2  12:30,9  \n",
      "3  12:34,0  \n",
      "4  12:37,5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset_clean/dev/dev_sent_emo.csv\", sep=\";\", encoding=\"ISO-8859-1\") \n",
    "\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92910900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sr No.                                          Utterance   Speaker  \\\n",
      "0       1     Oh my God, hes lost it. Hes totally lost it.    Phoebe   \n",
      "1       2                                              What?    Monica   \n",
      "2       3  Or! Or, we could go to the bank, close our acc...      Ross   \n",
      "3       4                                   Youre a genius!  Chandler   \n",
      "4       5            Aww, man, now we wont be bank buddies!      Joey   \n",
      "\n",
      "    Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode StartTime  \\\n",
      "0   sadness  negative            0             0       4        7   20:57,3   \n",
      "1  surprise  negative            0             1       4        7   21:01,9   \n",
      "2   neutral   neutral            1             0       4        4   12:24,7   \n",
      "3       joy  positive            1             1       4        4   12:32,3   \n",
      "4   sadness  negative            1             2       4        4   12:34,2   \n",
      "\n",
      "   EndTime  \n",
      "0  21:00,0  \n",
      "1  21:03,3  \n",
      "2  12:30,9  \n",
      "3  12:34,0  \n",
      "4  12:37,5  \n",
      "    Emotion                                          Utterance\n",
      "0   sadness     Oh my God, hes lost it. Hes totally lost it.\n",
      "1  surprise                                              What?\n",
      "2   neutral  Or! Or, we could go to the bank, close our acc...\n",
      "3       joy                                   Youre a genius!\n",
      "4   sadness            Aww, man, now we wont be bank buddies!\n"
     ]
    }
   ],
   "source": [
    "# Csv clean qui servira à fusionner avec les caractéristiques associés a chaque phrase\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le CSV\n",
    "df = pd.read_csv(\"dataset_clean/dev/dev_sent_emo.csv\", sep=\";\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Afficher les premières lignes pour vérifier la structure\n",
    "print(df.head())\n",
    "\n",
    "# Sélectionner les colonnes pertinentes pour la classification des émotions\n",
    "df_relevant = df[['Emotion', 'Utterance']]\n",
    "\n",
    "# Vérifier les valeurs uniques des émotions\n",
    "#print(df_relevant['Emotion'].unique())\n",
    "\n",
    "# Nettoyer les données \n",
    "df_relevant = df_relevant.dropna()  # Enlever les lignes avec des valeurs manquantes\n",
    "\n",
    "# Affichage pour vérifier\n",
    "print(df_relevant.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f739313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sadness' 'surprise' 'neutral' 'joy' 'anger' 'disgust' 'fear']\n",
      "Caractéristiques réduites après LDA : [[ 0.18763058 -0.45991126  0.22325307 -0.23112148]\n",
      " [ 0.61695606  1.7807293   0.07349628 -0.5387007 ]\n",
      " [ 0.97496253  0.87585413  0.61407363  0.3491623 ]\n",
      " [-2.9130845  -1.9372734  -0.8272921  -0.37198082]\n",
      " [ 0.5450134   0.21629457  1.2250175  -1.2241772 ]\n",
      " [ 1.1822509  -0.3264495   0.42009994 -1.5783043 ]\n",
      " [ 0.16136906 -0.3068881   0.316715   -0.9728636 ]\n",
      " [ 1.3389541  -0.96485937  0.2635329  -0.11932697]\n",
      " [ 0.1243787  -0.64978665  0.3897693   2.1538372 ]\n",
      " [-0.30290645  0.03140395 -1.1268449  -0.02998139]\n",
      " [-0.9182137   1.0929157  -0.8672093   0.1082748 ]\n",
      " [ 0.10158342  0.29726806  0.34089446 -0.08554813]\n",
      " [ 0.12234323 -0.7476404  -0.20410486 -2.4143047 ]\n",
      " [ 0.44068125 -0.48721322  1.2223823   0.90177816]\n",
      " [ 0.2642201   0.18513437 -1.6184535   0.17966986]\n",
      " [-0.6521063  -0.818561    2.2238228   1.097779  ]\n",
      " [ 1.3531508   0.00417111 -1.6129218   1.0307841 ]\n",
      " [ 0.8640672  -1.8942351   0.45528495  0.29829288]\n",
      " [-0.04791293 -0.05609201  1.2375393  -1.1701415 ]\n",
      " [-0.19526047  0.37022686 -0.37339133  1.123919  ]\n",
      " [ 1.0027184   0.8499313   1.403391    0.8494264 ]\n",
      " [-0.5186057   2.9338362   0.01901466  0.3218479 ]\n",
      " [-1.4695787   1.9569824  -0.12883244 -0.73695153]\n",
      " [ 0.13230239 -0.15455508 -0.8114674  -0.42846856]\n",
      " [-1.3288385  -0.6596418  -0.13302399  1.2369531 ]\n",
      " [-0.6403632  -0.33721885 -1.4327517   0.01251138]\n",
      " [-2.160372    0.03035148  1.0191628  -0.08980998]\n",
      " [-0.22047165 -0.37829667  0.01482521 -0.75061464]\n",
      " [ 1.5850945  -0.651691   -1.8543339  -0.08881149]\n",
      " [ 0.37003702  0.20521325 -0.47165117  1.1668706 ]]\n"
     ]
    }
   ],
   "source": [
    "import opensmile\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Charger le dataframe contenant les émotions\n",
    "df = pd.read_csv(\"dataset_clean/dev/dev_sent_emo.csv\", sep=\";\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Créer un dataframe avec les émotions et les énoncés\n",
    "df_relevant = df[['Emotion', 'Utterance']].dropna()\n",
    "\n",
    "# Afficher les émotions uniques\n",
    "print(df_relevant['Emotion'].unique())  # Vérifier toutes les émotions disponibles\n",
    "\n",
    "# Définir le chemin du dossier contenant les audios\n",
    "audio_folder = \"dataset_clean/dev/audios/\"\n",
    "audio_files = sorted(os.listdir(audio_folder))  # Trier les fichiers pour éviter le désordre\n",
    "\n",
    "# Sélectionner les 30 premiers fichiers audio\n",
    "audio_files = audio_files[:30]  # Limiter à 30 fichiers pour l'exemple\n",
    "\n",
    "# Créer un objet OpenSMILE avec une configuration valide\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,  # Configuration pour ComParE_2016\n",
    "    feature_level=opensmile.FeatureLevel.Functionals  # Niveau des fonctionnalités (moyennes, std, etc.)\n",
    ")\n",
    "\n",
    "# Initialiser le LabelEncoder pour convertir les étiquettes d'émotions en entiers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df_relevant['Emotion'].unique())  # Apprendre les étiquettes d'émotions\n",
    "\n",
    "# Extraire les caractéristiques audio et les émotions associées aux fichiers\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, audio_file in enumerate(audio_files):\n",
    "    audio_path = os.path.join(audio_folder, audio_file)\n",
    "    \n",
    "    # Extraire les caractéristiques du fichier audio\n",
    "    features = smile.process_file(audio_path)\n",
    "    \n",
    "    # Réinitialiser l'index pour enlever les niveaux multiples de MultiIndex\n",
    "    features_reset = features.reset_index()\n",
    "    \n",
    "    # Convertir les caractéristiques en tableau NumPy\n",
    "    features_array = features_reset.drop(['file', 'start', 'end'], axis=1).values\n",
    "    \n",
    "    # Ajouter les caractéristiques à la liste X\n",
    "    X.append(features_array.flatten())  # Aplatir le tableau pour obtenir une ligne unique\n",
    "    \n",
    "    # Extraire l'émotion associée à ce fichier audio depuis le dataframe df_relevant\n",
    "    emotion = df_relevant.iloc[i]['Emotion']\n",
    "    \n",
    "    # Ajouter l'émotion à la liste y après transformation en entier\n",
    "    y.append(label_encoder.transform([emotion])[0])\n",
    "\n",
    "# Convertir X et y en tableaux numpy\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Calculer n_components de manière dynamique pour qu'il soit valide\n",
    "n_classes = len(np.unique(y))  # Nombre d'émotions uniques\n",
    "n_features = X.shape[1]  # Nombre de caractéristiques extraites\n",
    "\n",
    "# S'assurer que n_components respecte la contrainte\n",
    "n_components = min(7, n_classes - 1, n_features)\n",
    "\n",
    "# Appliquer LDA (Linear Discriminant Analysis)\n",
    "lda = LinearDiscriminantAnalysis(n_components=n_components)  # Utiliser le nombre approprié de composantes\n",
    "lda.fit(X, y)  # Entraîner LDA sur les caractéristiques et les émotions\n",
    "\n",
    "# Appliquer LDA sur les caractéristiques des 30 audios\n",
    "X_lda = lda.transform(X)\n",
    "\n",
    "# Afficher les caractéristiques réduites\n",
    "print(f\"Caractéristiques réduites après LDA : {X_lda}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c4e7698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sadness' 'surprise' 'neutral' 'joy' 'anger' 'disgust' 'fear']\n",
      "Emotion: sadness\n",
      "Caractéristiques réduites: [-0.30892056  2.10776     0.9194853  -0.28072807  1.2371045 ]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [ 2.4576268  -1.1618607   0.41829222 -0.04484646  1.7159926 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [ 0.7509518   1.0920172  -0.5552484  -0.18605778 -1.48224   ]\n",
      "\n",
      "Emotion: joy\n",
      "Caractéristiques réduites: [-0.9777862  1.1477978 -3.5388823 -1.0706334  1.6620737]\n",
      "\n",
      "Emotion: sadness\n",
      "Caractéristiques réduites: [ 0.03864503 -1.4026675  -1.4354233   0.5754132   0.00469244]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.20707542  0.1900329   0.9090919   2.0996726  -1.029223  ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [ 0.10032827 -0.01784578  0.24079958 -0.28250873  0.03867029]\n",
      "\n",
      "Emotion: joy\n",
      "Caractéristiques réduites: [-1.3532248   0.609839   -0.39796513  0.26085073  0.9469808 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.3056341  -0.35666713 -0.8093043  -0.5295357  -0.8345828 ]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [-0.27893645 -0.11686168  0.5429298  -0.9551961  -1.2938064 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [ 0.00989445 -0.5378883  -0.47771224 -1.2179285   0.8076325 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [ 0.30486846  1.384335   -0.94535774 -0.40018278  1.1521568 ]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [ 0.79880285 -0.7581182  -0.15718125  0.3699729   0.6742295 ]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [-2.2619395  -0.75236535 -1.7250575   1.6679573   0.8470836 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.2729999  -1.16729     0.74411154 -0.62055385 -0.5420197 ]\n",
      "\n",
      "Emotion: joy\n",
      "Caractéristiques réduites: [-0.53109634  0.501037   -1.4582334  -0.20066886  1.3277724 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.96581644 -0.11576287  1.240031   -0.89626265 -0.35284758]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.79258823  0.42543066 -0.5485105   1.8040125  -0.7359029 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.09727995  0.6941756  -0.80979574  0.9335665   0.22318277]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [ 1.6388679  -0.37548593  0.48103023 -1.0223602  -1.717552  ]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [ 1.8036577  -0.70891476  0.8230167   0.16528831  0.37410414]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [ 2.80252    -1.959965    0.8147996  -1.3909055   0.49969238]\n",
      "\n",
      "Emotion: joy\n",
      "Caractéristiques réduites: [ 0.225936   -0.17129317 -1.8591759   0.99051195  0.7094263 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.6675898   0.10548982  0.36521187 -0.13011649 -0.5965922 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [ 0.6949489   0.27597624 -0.28024778  0.27790767  1.0681466 ]\n",
      "\n",
      "Emotion: joy\n",
      "Caractéristiques réduites: [ 0.29876873  0.48911113 -1.54532    -0.9114886   1.9536618 ]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [0.02208566 1.209205   1.5408921  0.3742104  1.1900014 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.3338959  -0.3348808   0.34749946  1.3156552  -0.3497031 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.3547409   0.03939096  1.1883546  -0.7831787  -0.5945796 ]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [-0.9563044  -0.54429764  0.95984435 -1.1066976  -1.2484902 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [ 1.4045907  -0.18672673  0.7938979  -1.6127472  -1.1004264 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-2.0502818 -0.0088641  1.0722219 -1.4327775 -0.3325596]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.05543511  0.60870564  0.8855428   0.96862584 -1.3725432 ]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [ 1.124291    0.7025953  -0.66103786 -0.48714465 -0.15960844]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [ 0.01096214  0.66871595 -0.48027542 -1.0059801   1.2491992 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.5186456 -0.2037135  1.095323   0.6770424  0.3553116]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [ 2.148981   -0.5778985   1.2061961  -2.9774058   0.03312074]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.1694004  -0.7821201   1.3733913  -0.61548245 -0.43263933]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [ 2.0663545  -1.6594325   0.09396892 -1.1321495   0.09371677]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [0.9804255 1.0013715 1.9221529 1.2721218 0.9097521]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [ 3.160337    0.7640964   0.0764666   0.9013234  -0.30151322]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.289189   -0.84944725 -0.26052907  0.2909748  -0.5812988 ]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [ 2.2210891   1.0037704  -0.07724166  0.04303776 -0.12052083]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [ 1.7701051   1.1903912  -1.7771851   0.92125654 -0.21568286]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [ 2.399545   -1.2105949   0.80022126 -0.5188284  -0.53803426]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [ 1.1861165   1.054925    0.00235776  0.5535309  -1.6217506 ]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [-0.06054115 -1.0767812   0.24530984  0.74837786  1.3024848 ]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [ 1.960581    2.788345   -0.43462387  1.920532   -1.6669765 ]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [0.66490155 1.9365149  2.3636124  1.7243499  1.3257225 ]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [ 1.6053845   1.4767151  -1.2660383   0.18344757 -0.33900902]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [ 0.8088951   0.28621852  0.9986007  -0.033033   -1.556434  ]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [-0.6402665   1.3131586  -0.03286079  1.4669011  -2.1150274 ]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [ 0.5052712   1.2588027  -0.95196915  0.16750184 -1.782551  ]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [ 1.4736958  -0.08573705  0.33800712 -0.704386    1.1845511 ]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [ 0.1888961  0.8253115 -1.7814997  0.6672301 -0.460845 ]\n",
      "\n",
      "Emotion: joy\n",
      "Caractéristiques réduites: [ 0.11240441 -0.63582075 -2.6116276  -0.07715751 -0.9000899 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.44957277  1.1685448   2.2713509   0.7376219  -0.45012653]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.6215425  -0.5412414  -0.18767104  0.37483913 -1.1361799 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.4827808  -0.05697267  1.1777884  -0.6050289  -0.43364066]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [ 3.0793169 -1.6787223  1.1033909 -2.114022   0.8612998]\n",
      "\n",
      "Emotion: sadness\n",
      "Caractéristiques réduites: [-0.8180502 -4.6207824 -0.5638046  3.9325724 -0.2500395]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.0027565  -0.08047608  0.66807324 -0.22361031 -1.1737452 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.7500098  -0.18863001  0.94596666  0.6732122  -0.17824127]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [-0.1211108  -0.61486155 -0.9234458  -1.3408605  -0.46036735]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [-0.5364024  -0.43847707  0.22621901 -0.28825694  0.7861153 ]\n",
      "\n",
      "Emotion: joy\n",
      "Caractéristiques réduites: [ 1.2756208  -0.1606805   0.29968593  0.27388352  0.44925797]\n",
      "\n",
      "Emotion: joy\n",
      "Caractéristiques réduites: [-0.43402067 -0.22231956 -2.1512043  -0.5929877  -0.47399285]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.538173   -0.4905616   0.34494197 -0.54841834 -0.21436313]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.13002682 -0.3771402  -1.0916799   0.15948358  0.4029302 ]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [ 1.3783756  -0.8112914  -1.0775124   0.03503442 -0.11417867]\n",
      "\n",
      "Emotion: joy\n",
      "Caractéristiques réduites: [-0.11473206 -1.8730876   0.08548652 -0.5391612  -1.5675229 ]\n",
      "\n",
      "Emotion: surprise\n",
      "Caractéristiques réduites: [ 0.48042947 -0.48465022 -1.466484    0.40050507  1.2578981 ]\n",
      "\n",
      "Emotion: anger\n",
      "Caractéristiques réduites: [ 0.5686485   1.9649402   0.05146916  0.8681762  -1.4920863 ]\n",
      "\n",
      "Emotion: disgust\n",
      "Caractéristiques réduites: [-0.09785099  1.9437783   2.34578     1.7206297   3.0992537 ]\n",
      "\n",
      "Emotion: joy\n",
      "Caractéristiques réduites: [-0.04357044  1.143512    0.2660833   0.0077621   1.449602  ]\n",
      "\n",
      "Emotion: joy\n",
      "Caractéristiques réduites: [-0.728257    0.3794176   0.7691872   1.1478331   0.55493397]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.48469162  0.32563084  1.3194754   2.0148044   2.9960692 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.4356209  -0.05156771  0.91201854 -0.7413976  -0.745834  ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [ 0.16151172 -0.2884798   0.43732238 -0.31326205  0.9484421 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.2989963   0.7343071  -0.9205142   0.63543755 -1.6925753 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.683163    0.05287843 -0.11578416 -1.6550933   1.0241612 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-2.4378257  -0.5967654  -0.99316317 -1.3514798   1.2922945 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.0266961  -1.3274894   0.5634954  -0.27150625  1.3287214 ]\n",
      "\n",
      "Emotion: joy\n",
      "Caractéristiques réduites: [-0.1439243  -0.52458215 -0.7375056   0.47919434  0.12167779]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [ 0.9269778  -1.9573922   0.00823304  2.1623657   0.36396712]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.5414049  -0.12055575 -0.9035222  -0.84515125 -0.30013424]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [ 0.8645031  -0.5421694   0.33434588 -0.5336621   0.8843321 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [ 0.96283525  0.8494426  -0.64916646  0.23140651 -1.6549572 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.6088356   1.6357093   1.0176446  -0.46793914 -0.6770223 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.772779   -0.95892006  1.2565051  -0.66648084  0.58121204]\n",
      "\n",
      "Emotion: joy\n",
      "Caractéristiques réduites: [-0.3679127   0.8640573  -0.40423205 -1.3278358  -0.9236075 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.02256978  0.47374195 -0.30395028 -0.80824924 -0.4068984 ]\n",
      "\n",
      "Emotion: sadness\n",
      "Caractéristiques réduites: [ 0.34458685 -3.577725    0.54570794  2.6369085  -1.02633   ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-0.62797475  1.609052   -0.16859007 -1.1209772   0.10905553]\n",
      "\n",
      "Emotion: joy\n",
      "Caractéristiques réduites: [-0.16634488  0.05959547 -3.3739789  -0.12690985  1.1916226 ]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.8629788   0.48084858  0.32390258 -0.34444177  0.53444743]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.6687081  -0.35324413  0.12102511 -1.7047777  -0.60092044]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.7925038  -0.32409388  1.2299484  -0.4629138  -0.54041827]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [ 0.71076906 -0.34096217 -0.78498346  0.18744716 -0.47001022]\n",
      "\n",
      "Emotion: neutral\n",
      "Caractéristiques réduites: [-1.2329383   0.5264499   0.2677833  -0.39903608  0.23448564]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import opensmile\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Charger le dataframe contenant les émotions\n",
    "df = pd.read_csv(\"dataset_clean/dev/dev_sent_emo.csv\", sep=\";\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Créer un dataframe avec les émotions et les énoncés\n",
    "df_relevant = df[['Emotion', 'Utterance']].dropna()\n",
    "\n",
    "# Afficher les émotions uniques\n",
    "print(df_relevant['Emotion'].unique())  # Vérifier toutes les émotions disponibles\n",
    "\n",
    "# Définir le chemin du dossier contenant les audios\n",
    "audio_folder = \"dataset_clean/dev/audios/\"\n",
    "audio_files = sorted(os.listdir(audio_folder))  # Trier les fichiers pour éviter le désordre\n",
    "\n",
    "# Sélectionner les 30 premiers fichiers audio\n",
    "audio_files = audio_files[:100]  # Limiter à 30 fichiers pour l'exemple\n",
    "\n",
    "# Créer un objet OpenSMILE avec une configuration valide\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,  # Configuration pour ComParE_2016\n",
    "    feature_level=opensmile.FeatureLevel.Functionals  # Niveau des fonctionnalités (moyennes, std, etc.)\n",
    ")\n",
    "\n",
    "# Initialiser le LabelEncoder pour convertir les étiquettes d'émotions en entiers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df_relevant['Emotion'].unique())  # Apprendre les étiquettes d'émotions\n",
    "\n",
    "# Extraire les caractéristiques audio et les émotions associées aux fichiers\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, audio_file in enumerate(audio_files):\n",
    "    audio_path = os.path.join(audio_folder, audio_file)\n",
    "    \n",
    "    # Extraire les caractéristiques du fichier audio\n",
    "    features = smile.process_file(audio_path)\n",
    "    \n",
    "    # Réinitialiser l'index pour enlever les niveaux multiples de MultiIndex\n",
    "    features_reset = features.reset_index()\n",
    "    \n",
    "    # Convertir les caractéristiques en tableau NumPy\n",
    "    features_array = features_reset.drop(['file', 'start', 'end'], axis=1).values\n",
    "    \n",
    "    # Ajouter les caractéristiques à la liste X\n",
    "    X.append(features_array.flatten())  # Aplatir le tableau pour obtenir une ligne unique\n",
    "    \n",
    "    # Extraire l'émotion associée à ce fichier audio depuis le dataframe df_relevant\n",
    "    emotion = df_relevant.iloc[i]['Emotion']\n",
    "    \n",
    "    # Ajouter l'émotion à la liste y après transformation en entier\n",
    "    y.append(label_encoder.transform([emotion])[0])\n",
    "\n",
    "# Convertir X et y en tableaux numpy\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Calculer n_components de manière dynamique pour qu'il soit valide\n",
    "n_classes = len(np.unique(y))  # Nombre d'émotions uniques\n",
    "n_features = X.shape[1]  # Nombre de caractéristiques extraites\n",
    "\n",
    "# S'assurer que n_components respecte la contrainte\n",
    "n_components = min(7, n_classes - 1, n_features)\n",
    "\n",
    "# Appliquer LDA (Linear Discriminant Analysis)\n",
    "lda = LinearDiscriminantAnalysis(n_components=n_components)  # Utiliser le nombre approprié de composantes\n",
    "lda.fit(X, y)  # Entraîner LDA sur les caractéristiques et les émotions\n",
    "\n",
    "# Appliquer LDA sur les caractéristiques des 30 audios\n",
    "X_lda = lda.transform(X)\n",
    "\n",
    "# Affichage des caractéristiques réduites avec les émotions associées\n",
    "for i in range(len(X_lda)):\n",
    "    emotion = label_encoder.inverse_transform([y[i]])[0]  # Convertir le label numérique en émotion\n",
    "    print(f\"Emotion: {emotion}\")\n",
    "    print(f\"Caractéristiques réduites: {X_lda[i]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5986366b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne des caractéristiques pour l'émotion 'anger': [ 0.7829712   0.76572126 -0.14205004  0.55117667 -0.47953346]\n",
      "Moyenne des caractéristiques pour l'émotion 'disgust': [-0.09785099  1.9437783   2.34578     1.7206297   3.0992537 ]\n",
      "Moyenne des caractéristiques pour l'émotion 'fear': [nan nan nan nan nan]\n",
      "Moyenne des caractéristiques pour l'émotion 'joy': [-0.21058139  0.11475594 -1.1898345  -0.12048624  0.46441406]\n",
      "Moyenne des caractéristiques pour l'émotion 'neutral': [-0.63854116  0.00381264  0.25352693 -0.15068047 -0.11287099]\n",
      "Moyenne des caractéristiques pour l'émotion 'sadness': [-0.18593472 -1.8733537  -0.13350868  1.7160416  -0.00864312]\n",
      "Moyenne des caractéristiques pour l'émotion 'surprise': [ 1.2608408  -0.42920962  0.26707733 -0.44072157  0.16912955]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "import opensmile\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Charger le dataframe contenant les émotions\n",
    "df = pd.read_csv(\"dataset_clean/dev/dev_sent_emo.csv\", sep=\";\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Créer un dataframe avec les émotions et les énoncés\n",
    "df_relevant = df[['Emotion', 'Utterance']].dropna()\n",
    "\n",
    "# Définir le chemin du dossier contenant les audios\n",
    "audio_folder = \"dataset_clean/dev/audios/\"\n",
    "audio_files = sorted(os.listdir(audio_folder))  # Trier les fichiers pour éviter le désordre\n",
    "\n",
    "# Sélectionner les 100 premiers fichiers audio\n",
    "audio_files = audio_files[:100]  # Limiter à 100 fichiers pour l'exemple\n",
    "\n",
    "# Créer un objet OpenSMILE avec une configuration valide\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,  # Configuration pour ComParE_2016\n",
    "    feature_level=opensmile.FeatureLevel.Functionals  # Niveau des fonctionnalités (moyennes, std, etc.)\n",
    ")\n",
    "\n",
    "# Initialiser le LabelEncoder pour convertir les étiquettes d'émotions en entiers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df_relevant['Emotion'].unique())  # Apprendre les étiquettes d'émotions\n",
    "\n",
    "# Extraire les caractéristiques audio et les émotions associées aux fichiers\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, audio_file in enumerate(audio_files):\n",
    "    audio_path = os.path.join(audio_folder, audio_file)\n",
    "    \n",
    "    # Extraire les caractéristiques du fichier audio\n",
    "    features = smile.process_file(audio_path)\n",
    "    \n",
    "    # Réinitialiser l'index pour enlever les niveaux multiples de MultiIndex\n",
    "    features_reset = features.reset_index()\n",
    "    \n",
    "    # Convertir les caractéristiques en tableau NumPy\n",
    "    features_array = features_reset.drop(['file', 'start', 'end'], axis=1).values\n",
    "    \n",
    "    # Ajouter les caractéristiques à la liste X\n",
    "    X.append(features_array.flatten())  # Aplatir le tableau pour obtenir une ligne unique\n",
    "    \n",
    "    # Extraire l'émotion associée à ce fichier audio depuis le dataframe df_relevant\n",
    "    emotion = df_relevant.iloc[i]['Emotion']\n",
    "    \n",
    "    # Ajouter l'émotion à la liste y après transformation en entier\n",
    "    y.append(label_encoder.transform([emotion])[0])\n",
    "\n",
    "# Convertir X et y en tableaux numpy\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Calculer n_components de manière dynamique pour qu'il soit valide\n",
    "n_classes = len(np.unique(y))  # Nombre d'émotions uniques\n",
    "n_features = X.shape[1]  # Nombre de caractéristiques extraites\n",
    "\n",
    "# S'assurer que n_components respecte la contrainte\n",
    "n_components = min(7, n_classes - 1, n_features)\n",
    "\n",
    "# Appliquer LDA (Linear Discriminant Analysis)\n",
    "lda = LinearDiscriminantAnalysis(n_components=n_components)  # Utiliser le nombre approprié de composantes\n",
    "lda.fit(X, y)  # Entraîner LDA sur les caractéristiques et les émotions\n",
    "\n",
    "# Appliquer LDA sur les caractéristiques des 100 audios\n",
    "X_lda = lda.transform(X)\n",
    "\n",
    "# Calculer la moyenne des caractéristiques pour chaque émotion\n",
    "emotion_medians = {}\n",
    "for emotion in label_encoder.classes_:\n",
    "    # Récupérer les indices des fichiers audio associés à chaque émotion\n",
    "    emotion_indices = np.where(y == label_encoder.transform([emotion])[0])[0]\n",
    "    \n",
    "    # Extraire les caractéristiques LDA des fichiers audio associés à l'émotion\n",
    "    emotion_features = X_lda[emotion_indices]\n",
    "    \n",
    "    # Calculer la moyenne des caractéristiques pour cette émotion\n",
    "    emotion_medians[emotion] = np.mean(emotion_features, axis=0)\n",
    "\n",
    "# Afficher la moyenne des caractéristiques réduites par émotion\n",
    "for emotion, mean in emotion_medians.items():\n",
    "    print(f\"Moyenne des caractéristiques pour l'émotion '{emotion}': {mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93a81bf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components cannot be larger than min(n_features, n_classes - 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Appliquer LDA (Linear Discriminant Analysis)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m lda \u001b[38;5;241m=\u001b[39m LinearDiscriminantAnalysis(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)  \u001b[38;5;66;03m# Utiliser 2 composantes pour la réduction\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m lda\u001b[38;5;241m.\u001b[39mfit(X, y)  \u001b[38;5;66;03m# Entraîner LDA sur les caractéristiques et les émotions\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Appliquer LDA sur les caractéristiques des 30 audios\u001b[39;00m\n\u001b[0;32m     58\u001b[0m X_lda \u001b[38;5;241m=\u001b[39m lda\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:693\u001b[0m, in \u001b[0;36mLinearDiscriminantAnalysis.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m>\u001b[39m max_components:\n\u001b[1;32m--> 693\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    694\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components cannot be larger than min(n_features, n_classes - 1).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: n_components cannot be larger than min(n_features, n_classes - 1)."
     ]
    }
   ],
   "source": [
    "import opensmile\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Charger le dataframe contenant les émotions\n",
    "df = pd.read_csv(\"dataset_clean/dev/dev_sent_emo.csv\", sep=\";\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Définir le chemin du dossier contenant les audios\n",
    "audio_folder = \"dataset_clean/dev/audios/\"\n",
    "audio_files = sorted(os.listdir(audio_folder))  # Trier les fichiers pour éviter le désordre\n",
    "\n",
    "# Sélectionner les 30 premiers fichiers audio\n",
    "audio_files = audio_files[:30]  # Limiter à 30 fichiers pour l'exemple\n",
    "\n",
    "# Créer un objet OpenSMILE avec une configuration valide\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,  # Configuration pour ComParE_2016\n",
    "    feature_level=opensmile.FeatureLevel.Functionals  # Niveau des fonctionnalités (moyennes, std, etc.)\n",
    ")\n",
    "\n",
    "# Extraire les caractéristiques audio et les émotions associées aux fichiers\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, audio_file in enumerate(audio_files):\n",
    "    audio_path = os.path.join(audio_folder, audio_file)\n",
    "    \n",
    "    # Extraire les caractéristiques du fichier audio\n",
    "    features = smile.process_file(audio_path)\n",
    "    \n",
    "    # Réinitialiser l'index pour enlever les niveaux multiples de MultiIndex\n",
    "    features_reset = features.reset_index()\n",
    "    \n",
    "    # Convertir les caractéristiques en tableau NumPy\n",
    "    features_array = features_reset.drop(['file', 'start', 'end'], axis=1).values\n",
    "    \n",
    "    # Ajouter les caractéristiques à la liste X\n",
    "    X.append(features_array.flatten())  # Aplatir le tableau pour obtenir une ligne unique\n",
    "    \n",
    "    # Extraire l'émotion associée à ce fichier audio depuis le dataframe df\n",
    "    # Assumer que les fichiers audio sont triés de manière correspondante avec le dataframe\n",
    "    emotion = df.iloc[i]['Emotion']\n",
    "    \n",
    "    # Ajouter l'émotion à la liste y\n",
    "    y.append(emotion)\n",
    "\n",
    "# Convertir X et y en tableaux numpy\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Appliquer LDA (Linear Discriminant Analysis)\n",
    "lda = LinearDiscriminantAnalysis(n_components=7)  # Utiliser 2 composantes pour la réduction\n",
    "lda.fit(X, y)  # Entraîner LDA sur les caractéristiques et les émotions\n",
    "\n",
    "# Appliquer LDA sur les caractéristiques des 30 audios\n",
    "X_lda = lda.transform(X)\n",
    "\n",
    "# Afficher les caractéristiques réduites\n",
    "print(f\"Caractéristiques réduites après LDA : {X_lda}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3d2d6ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "LibsndfileError",
     "evalue": "Error opening 'C:\\\\Users\\\\boucceredj\\\\Desktop\\\\Master_IISC_2eme_annee\\\\projet_synthese\\\\notreChoix\\\\code\\\\train\\\\train_audio\\\\your_audio.wav': System error.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m smile \u001b[38;5;241m=\u001b[39m opensmile\u001b[38;5;241m.\u001b[39mSmile(\n\u001b[0;32m      7\u001b[0m     feature_set\u001b[38;5;241m=\u001b[39mopensmile\u001b[38;5;241m.\u001b[39mFeatureSet\u001b[38;5;241m.\u001b[39mComParE_2016,  \u001b[38;5;66;03m# Jeu de caractéristiques\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     feature_level\u001b[38;5;241m=\u001b[39mopensmile\u001b[38;5;241m.\u001b[39mFeatureLevel\u001b[38;5;241m.\u001b[39mFunctionals,  \u001b[38;5;66;03m# Niveau des fonctionnalités\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Traiter un fichier audio\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m smile\u001b[38;5;241m.\u001b[39mprocess_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain/train_audio/your_audio.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Convertir les caractéristiques extraites en DataFrame pour une manipulation facile\u001b[39;00m\n\u001b[0;32m     15\u001b[0m audio_features_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(audio_features)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\feature.py:391\u001b[0m, in \u001b[0;36mFeature.process_file\u001b[1;34m(self, file, start, end, root, process_func_args)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_file\u001b[39m(\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    360\u001b[0m     file: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m     process_func_args: typing\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, typing\u001b[38;5;241m.\u001b[39mAny] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    366\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Extract features from an audio file.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    389\u001b[0m \n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 391\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39mprocess_file(\n\u001b[0;32m    392\u001b[0m         file,\n\u001b[0;32m    393\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    394\u001b[0m         end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m    395\u001b[0m         root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    396\u001b[0m         process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    397\u001b[0m     )\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_series_to_frame(series)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:344\u001b[0m, in \u001b[0;36mProcess.process_file\u001b[1;34m(self, file, start, end, root, process_func_args)\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_index_wo_segment(index, root)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m     y, files, starts, ends \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_file(\n\u001b[0;32m    345\u001b[0m         file,\n\u001b[0;32m    346\u001b[0m         root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    347\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    348\u001b[0m         end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m    349\u001b[0m         process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    350\u001b[0m     )\n\u001b[0;32m    352\u001b[0m     index \u001b[38;5;241m=\u001b[39m audformat\u001b[38;5;241m.\u001b[39msegmented_index(files, starts, ends)\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:259\u001b[0m, in \u001b[0;36mProcess._process_file\u001b[1;34m(self, file, idx, root, start, end, process_func_args)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     end \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mto_timedelta(end, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate)\n\u001b[1;32m--> 259\u001b[0m signal, sampling_rate \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mread_audio(\n\u001b[0;32m    260\u001b[0m     file,\n\u001b[0;32m    261\u001b[0m     start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    262\u001b[0m     end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m    263\u001b[0m     root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    264\u001b[0m )\n\u001b[0;32m    266\u001b[0m y, files, starts, ends \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_signal(\n\u001b[0;32m    267\u001b[0m     signal,\n\u001b[0;32m    268\u001b[0m     sampling_rate,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m     process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    273\u001b[0m )\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_offset\u001b[39m(duration, sampling_rate):\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;66;03m# Ensure we get the same precision\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# by storing what is lost due to rounding\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# when reading the file\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\utils.py:141\u001b[0m, in \u001b[0;36mread_audio\u001b[1;34m(file, start, end, root)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     duration \u001b[38;5;241m=\u001b[39m end\u001b[38;5;241m.\u001b[39mtotal_seconds() \u001b[38;5;241m-\u001b[39m offset\n\u001b[1;32m--> 141\u001b[0m signal, sampling_rate \u001b[38;5;241m=\u001b[39m audiofile\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    142\u001b[0m     file,\n\u001b[0;32m    143\u001b[0m     always_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    144\u001b[0m     offset\u001b[38;5;241m=\u001b[39moffset,\n\u001b[0;32m    145\u001b[0m     duration\u001b[38;5;241m=\u001b[39mduration,\n\u001b[0;32m    146\u001b[0m )\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signal, sampling_rate\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audiofile\\core\\io.py:411\u001b[0m, in \u001b[0;36mread\u001b[1;34m(file, duration, offset, always_2d, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m         stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 411\u001b[0m     signal, sampling_rate \u001b[38;5;241m=\u001b[39m soundfile\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    412\u001b[0m         file,\n\u001b[0;32m    413\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    414\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    415\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    416\u001b[0m         always_2d\u001b[38;5;241m=\u001b[39malways_2d,\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# [samples, channels] => [channels, samples]\u001b[39;00m\n\u001b[0;32m    420\u001b[0m signal \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\soundfile.py:305\u001b[0m, in \u001b[0;36mread\u001b[1;34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(file, frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, always_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    220\u001b[0m          fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, samplerate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m          \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, subtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, endian\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    222\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Provide audio data from a sound file as NumPy array.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m    By default, the whole file is read from the beginning, but the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    303\u001b[0m \n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m SoundFile(file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, samplerate, channels,\n\u001b[0;32m    306\u001b[0m                    subtype, endian, \u001b[38;5;28mformat\u001b[39m, closefd) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    307\u001b[0m         frames \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39m_prepare_read(start, stop, frames)\n\u001b[0;32m    308\u001b[0m         data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(frames, dtype, always_2d, fill_value, out)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\soundfile.py:690\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bitrate_mode \u001b[38;5;241m=\u001b[39m bitrate_mode\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    689\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(file, mode_int, closefd)\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\soundfile.py:1265\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_ptr \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mNULL:\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;66;03m# get the actual error code\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mframes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'C:\\\\Users\\\\boucceredj\\\\Desktop\\\\Master_IISC_2eme_annee\\\\projet_synthese\\\\notreChoix\\\\code\\\\train\\\\train_audio\\\\your_audio.wav': System error."
     ]
    }
   ],
   "source": [
    "import opensmile\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "# Initialiser openSMILE avec les paramètres désirés\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,  # Jeu de caractéristiques\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,  # Niveau des fonctionnalités\n",
    ")\n",
    "\n",
    "# Traiter un fichier audio\n",
    "audio_features = smile.process_file('train/train_audio/your_audio.wav')\n",
    "\n",
    "# Convertir les caractéristiques extraites en DataFrame pour une manipulation facile\n",
    "audio_features_df = pd.DataFrame(audio_features)\n",
    "\n",
    "# Afficher la forme des données (nombre de lignes et de colonnes)\n",
    "print(f\"Forme des données extraites : {audio_features_df.shape}\")\n",
    "\n",
    "# Vérifier le nombre de lignes et de colonnes\n",
    "n_samples, n_features = audio_features_df.shape\n",
    "\n",
    "# Appliquer PCA en fonction du nombre de samples\n",
    "n_components = min(2, n_features)  # Si n_samples = 1, on applique PCA à 2 composants max, sinon à min(100, n_features)\n",
    "print(f\"Nombre de composantes pour PCA : {n_components}\")\n",
    "\n",
    "# Appliquer PCA pour réduire la dimensionnalité\n",
    "pca = PCA(n_components=n_components)\n",
    "reduced_features = pca.fit_transform(audio_features_df)\n",
    "\n",
    "# Créer un DataFrame avec les caractéristiques réduites\n",
    "reduced_features_df = pd.DataFrame(reduced_features)\n",
    "\n",
    "# Afficher les premières lignes des caractéristiques réduites\n",
    "print(f\"Caractéristiques après réduction de dimension :\")\n",
    "print(reduced_features_df.head())\n",
    "\n",
    "# Optionnel : Enregistrer les caractéristiques réduites dans un fichier CSV\n",
    "#reduced_features_df.to_csv('reduced_audio_features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213142ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Chemin vers l'exécutable OpenSMILE\n",
    "smile_exec_path = \"path_to_opensmile/SMILExtract\"  # Remplace par le chemin exact vers SMILExtract\n",
    "\n",
    "# Chemin vers le fichier de configuration eGeMAPS\n",
    "config_path = \"path_to_opensmile/config/gemaps/eGeMAPSv02.conf\"\n",
    "\n",
    "# Dossier contenant les fichiers audio\n",
    "audio_folder = \"path_to_audio_files\"\n",
    "output_folder = \"path_to_output_files\"\n",
    "\n",
    "# Créer le dossier de sortie s'il n'existe pas\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Parcourir les fichiers audio dans le dossier\n",
    "for audio_file in os.listdir(audio_folder):\n",
    "    if audio_file.endswith(\".wav\") or audio_file.endswith(\".mp3\"):\n",
    "        input_audio_path = os.path.join(audio_folder, audio_file)\n",
    "        output_csv_path = os.path.join(output_folder, audio_file.replace(\".wav\", \".csv\").replace(\".mp3\", \".csv\"))\n",
    "\n",
    "        print(f\"Traitement de {audio_file}...\")\n",
    "\n",
    "        # Commande OpenSMILE\n",
    "        command = [\n",
    "            smile_exec_path,\n",
    "            \"-C\", config_path,               # Configuration eGeMAPS\n",
    "            \"-I\", input_audio_path,          # Fichier audio en entrée\n",
    "            \"-O\", output_csv_path            # Fichier CSV en sortie\n",
    "        ]\n",
    "\n",
    "        # Exécuter la commande\n",
    "        try:\n",
    "            subprocess.run(command, check=True)\n",
    "            print(f\"Fichier traité avec succès : {output_csv_path}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Erreur lors du traitement de {audio_file} : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be8d71db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<FeatureSet.ComParE_2016: 'compare/ComParE_2016'>, <FeatureSet.GeMAPS: 'gemaps/v01a/GeMAPSv01a'>, <FeatureSet.GeMAPSv01b: 'gemaps/v01b/GeMAPSv01b'>, <FeatureSet.eGeMAPS: 'egemaps/v01a/eGeMAPSv01a'>, <FeatureSet.eGeMAPSv01b: 'egemaps/v01b/eGeMAPSv01b'>, <FeatureSet.eGeMAPSv02: 'egemaps/v02/eGeMAPSv02'>, <FeatureSet.emobase: 'emobase/emobase'>]\n"
     ]
    }
   ],
   "source": [
    "import opensmile\n",
    "\n",
    "# Afficher les configurations disponibles dans FeatureSet\n",
    "print(list(opensmile.FeatureSet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94774778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     file  start                       end  \\\n",
      "0  dataset_clean/dev/audios/dia0_utt0.wav 0 days 0 days 00:00:02.794666667   \n",
      "\n",
      "   audspec_lengthL1norm_sma_range  audspec_lengthL1norm_sma_maxPos  \\\n",
      "0                        1.893929                         0.220588   \n",
      "\n",
      "   audspec_lengthL1norm_sma_minPos  audspec_lengthL1norm_sma_quartile1  \\\n",
      "0                         0.172794                            0.706538   \n",
      "\n",
      "   audspec_lengthL1norm_sma_quartile2  audspec_lengthL1norm_sma_quartile3  \\\n",
      "0                            1.049367                            1.491009   \n",
      "\n",
      "   audspec_lengthL1norm_sma_iqr1-2  ...  mfcc_sma_de[14]_peakRangeAbs  \\\n",
      "0                          0.34283  ...                       6.21958   \n",
      "\n",
      "   mfcc_sma_de[14]_peakRangeRel  mfcc_sma_de[14]_peakMeanAbs  \\\n",
      "0                      0.612551                     2.319552   \n",
      "\n",
      "   mfcc_sma_de[14]_peakMeanMeanDist  mfcc_sma_de[14]_peakMeanRel  \\\n",
      "0                          2.281682                    18.470751   \n",
      "\n",
      "   mfcc_sma_de[14]_minRangeRel  mfcc_sma_de[14]_meanRisingSlope  \\\n",
      "0                     0.666554                        107.25087   \n",
      "\n",
      "   mfcc_sma_de[14]_stddevRisingSlope  mfcc_sma_de[14]_meanFallingSlope  \\\n",
      "0                          41.357243                        106.058647   \n",
      "\n",
      "   mfcc_sma_de[14]_stddevFallingSlope  \n",
      "0                           49.927883  \n",
      "\n",
      "[1 rows x 6376 columns]\n",
      "Extraction terminée pour : dataset_clean/dev/audios/dia0_utt0.wav\n"
     ]
    }
   ],
   "source": [
    "import opensmile\n",
    "import os\n",
    "\n",
    "# Définir le chemin du dossier contenant les audios\n",
    "audio_folder = \"dataset_clean/dev/audios/\"\n",
    "audio_files = sorted(os.listdir(audio_folder))  # Trier les fichiers pour éviter le désordre\n",
    "first_audio = os.path.join(audio_folder, audio_files[0])  # Prendre le premier fichier\n",
    "\n",
    "# Créer un objet OpenSMILE avec une configuration valide\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,  # Configuration pour ComParE_2016\n",
    "    feature_level=opensmile.FeatureLevel.Functionals  # Niveau des fonctionnalités (moyennes, std, etc.)\n",
    ")\n",
    "\n",
    "# Extraire les caractéristiques audio du premier fichier\n",
    "features = smile.process_file(first_audio)\n",
    "\n",
    "# Afficher les caractéristiques dans la console\n",
    "# Afficher les premières lignes du DataFrame sans index multi-niveau\n",
    "# Réinitialiser l'index pour enlever les niveaux multiples\n",
    "features_reset = features.reset_index()\n",
    "\n",
    "# Afficher les premières lignes de manière plus lisible\n",
    "print(features_reset.head())  # Affiche les 5 premières lignes du DataFrame\n",
    "print(f\"Extraction terminée pour : {first_audio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5d52eec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of samples must be more than the number of classes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Appliquer LDA\u001b[39;00m\n\u001b[0;32m     37\u001b[0m lda \u001b[38;5;241m=\u001b[39m LinearDiscriminantAnalysis(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m lda\u001b[38;5;241m.\u001b[39mfit(X, y)  \u001b[38;5;66;03m# Entraîner LDA sur les deux premiers échantillons\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Appliquer LDA sur les caractéristiques des deux audios\u001b[39;00m\n\u001b[0;32m     41\u001b[0m X_lda \u001b[38;5;241m=\u001b[39m lda\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:668\u001b[0m, in \u001b[0;36mLinearDiscriminantAnalysis.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    665\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m==\u001b[39m n_classes:\n\u001b[1;32m--> 668\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    669\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of samples must be more than the number of classes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    670\u001b[0m     )\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpriors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# estimate priors from sample\u001b[39;00m\n\u001b[0;32m    673\u001b[0m     _, cnts \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39munique_counts(y)  \u001b[38;5;66;03m# non-negative ints\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: The number of samples must be more than the number of classes."
     ]
    }
   ],
   "source": [
    "import opensmile\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Définir le chemin du dossier contenant les audios\n",
    "audio_folder = \"dataset_clean/dev/audios/\"\n",
    "audio_files = sorted(os.listdir(audio_folder))  # Trier les fichiers pour éviter le désordre\n",
    "first_audio = os.path.join(audio_folder, audio_files[0])  # Prendre le premier fichier\n",
    "second_audio = os.path.join(audio_folder, audio_files[1])  # Prendre le deuxième fichier\n",
    "\n",
    "# Créer un objet OpenSMILE avec une configuration valide\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,  # Configuration pour ComParE_2016\n",
    "    feature_level=opensmile.FeatureLevel.Functionals  # Niveau des fonctionnalités (moyennes, std, etc.)\n",
    ")\n",
    "\n",
    "# Extraire les caractéristiques audio du premier et deuxième fichier\n",
    "features_first = smile.process_file(first_audio)\n",
    "features_second = smile.process_file(second_audio)\n",
    "\n",
    "# Réinitialiser l'index pour enlever les niveaux multiples de MultiIndex\n",
    "features_first_reset = features_first.reset_index()\n",
    "features_second_reset = features_second.reset_index()\n",
    "\n",
    "# Convertir les caractéristiques en matrices NumPy pour LDA\n",
    "X_first_audio = features_first_reset.drop(['file', 'start', 'end'], axis=1).values\n",
    "X_second_audio = features_second_reset.drop(['file', 'start', 'end'], axis=1).values\n",
    "\n",
    "# Ajouter les deux échantillons (pour que LDA puisse fonctionner)\n",
    "X = np.vstack([X_first_audio, X_second_audio])\n",
    "\n",
    "# Étiquettes correspondantes pour chaque audio (par exemple, 'sadness' pour le premier et 'joy' pour le deuxième)\n",
    "y = np.array(['sadness', 'joy'])\n",
    "\n",
    "# Appliquer LDA\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "lda.fit(X, y)  # Entraîner LDA sur les deux premiers échantillons\n",
    "\n",
    "# Appliquer LDA sur les caractéristiques des deux audios\n",
    "X_lda = lda.transform(X)\n",
    "\n",
    "# Afficher les caractéristiques réduites\n",
    "print(f\"Caractéristiques réduites après LDA : {X_lda}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab8b28d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Supposons que `df_features` contient tes données extraites et `labels` contient les étiquettes émotionnelles\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X \u001b[38;5;241m=\u001b[39m df_features\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion_label\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# X : toutes les caractéristiques sauf l'étiquette émotionnelle\u001b[39;00m\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m df_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion_label\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# y : les étiquettes émotionnelles\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Scaler les données (facultatif mais recommandé pour certains modèles)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_features' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Supposons que `df_features` contient tes données extraites et `labels` contient les étiquettes émotionnelles\n",
    "X = df_features.drop('emotion_label', axis=1)  # X : toutes les caractéristiques sauf l'étiquette émotionnelle\n",
    "y = df_features['emotion_label']  # y : les étiquettes émotionnelles\n",
    "\n",
    "# Scaler les données (facultatif mais recommandé pour certains modèles)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Séparer en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modèle RandomForest pour obtenir l'importance des caractéristiques\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Affichage de l'importance des caractéristiques\n",
    "feature_importances = rf.feature_importances_\n",
    "important_features = sorted(zip(X.columns, feature_importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(important_features[:10])  # Affiche les 10 caractéristiques les plus importantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94fc89de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traitement du dossier train...\n",
      "Progression : 100 fichiers traités\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 56\u001b[0m\n\u001b[0;32m     52\u001b[0m utterance_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# Extraction des caractéristiques avec opensmile\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m     features_df \u001b[38;5;241m=\u001b[39m smile\u001b[38;5;241m.\u001b[39mprocess_file(audio_path)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErreur lors de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextraction pour \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\feature.py:391\u001b[0m, in \u001b[0;36mFeature.process_file\u001b[1;34m(self, file, start, end, root, process_func_args)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_file\u001b[39m(\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    360\u001b[0m     file: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m     process_func_args: typing\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, typing\u001b[38;5;241m.\u001b[39mAny] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    366\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Extract features from an audio file.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    389\u001b[0m \n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 391\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39mprocess_file(\n\u001b[0;32m    392\u001b[0m         file,\n\u001b[0;32m    393\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    394\u001b[0m         end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m    395\u001b[0m         root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    396\u001b[0m         process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    397\u001b[0m     )\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_series_to_frame(series)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:344\u001b[0m, in \u001b[0;36mProcess.process_file\u001b[1;34m(self, file, start, end, root, process_func_args)\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_index_wo_segment(index, root)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m     y, files, starts, ends \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_file(\n\u001b[0;32m    345\u001b[0m         file,\n\u001b[0;32m    346\u001b[0m         root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    347\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    348\u001b[0m         end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m    349\u001b[0m         process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    350\u001b[0m     )\n\u001b[0;32m    352\u001b[0m     index \u001b[38;5;241m=\u001b[39m audformat\u001b[38;5;241m.\u001b[39msegmented_index(files, starts, ends)\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:266\u001b[0m, in \u001b[0;36mProcess._process_file\u001b[1;34m(self, file, idx, root, start, end, process_func_args)\u001b[0m\n\u001b[0;32m    257\u001b[0m     end \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mto_timedelta(end, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate)\n\u001b[0;32m    259\u001b[0m signal, sampling_rate \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mread_audio(\n\u001b[0;32m    260\u001b[0m     file,\n\u001b[0;32m    261\u001b[0m     start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    262\u001b[0m     end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m    263\u001b[0m     root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    264\u001b[0m )\n\u001b[1;32m--> 266\u001b[0m y, files, starts, ends \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_signal(\n\u001b[0;32m    267\u001b[0m     signal,\n\u001b[0;32m    268\u001b[0m     sampling_rate,\n\u001b[0;32m    269\u001b[0m     idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[0;32m    270\u001b[0m     root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    271\u001b[0m     file\u001b[38;5;241m=\u001b[39mfile,\n\u001b[0;32m    272\u001b[0m     process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    273\u001b[0m )\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_offset\u001b[39m(duration, sampling_rate):\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;66;03m# Ensure we get the same precision\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# by storing what is lost due to rounding\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# when reading the file\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     duration_at_sample \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mto_timedelta(\n\u001b[0;32m    280\u001b[0m         audmath\u001b[38;5;241m.\u001b[39msamples(duration\u001b[38;5;241m.\u001b[39mtotal_seconds(), sampling_rate) \u001b[38;5;241m/\u001b[39m sampling_rate\n\u001b[0;32m    281\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:690\u001b[0m, in \u001b[0;36mProcess._process_signal\u001b[1;34m(self, signal, sampling_rate, idx, root, file, start, end, process_func_args)\u001b[0m\n\u001b[0;32m    687\u001b[0m         signal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(signal, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, num_pad)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    689\u001b[0m \u001b[38;5;66;03m# Process signal\u001b[39;00m\n\u001b[1;32m--> 690\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\n\u001b[0;32m    691\u001b[0m     signal,\n\u001b[0;32m    692\u001b[0m     sampling_rate,\n\u001b[0;32m    693\u001b[0m     idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[0;32m    694\u001b[0m     root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    695\u001b[0m     file\u001b[38;5;241m=\u001b[39mfile,\n\u001b[0;32m    696\u001b[0m     process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    697\u001b[0m )\n\u001b[0;32m    699\u001b[0m \u001b[38;5;66;03m# Create index\u001b[39;00m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwin_dur \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:975\u001b[0m, in \u001b[0;36mProcess._call\u001b[1;34m(self, signal, sampling_rate, idx, root, file, process_func_args)\u001b[0m\n\u001b[0;32m    973\u001b[0m     y \u001b[38;5;241m=\u001b[39m [_helper(frames[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, idx]) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_frames)]\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 975\u001b[0m     y \u001b[38;5;241m=\u001b[39m _helper(signal)\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:958\u001b[0m, in \u001b[0;36mProcess._call.<locals>._helper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    949\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_func(\n\u001b[0;32m    950\u001b[0m             np\u001b[38;5;241m.\u001b[39matleast_2d(channel),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m x\n\u001b[0;32m    956\u001b[0m     ]\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_func(\n\u001b[0;32m    959\u001b[0m         x,\n\u001b[0;32m    960\u001b[0m         sampling_rate,\n\u001b[0;32m    961\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mspecial_args,\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprocess_func_args,\n\u001b[0;32m    963\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\opensmile\\core\\smile.py:285\u001b[0m, in \u001b[0;36mSmile._extract\u001b[1;34m(self, signal, sampling_rate)\u001b[0m\n\u001b[0;32m    282\u001b[0m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampleRate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sampling_rate\n\u001b[0;32m    283\u001b[0m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnBits\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m--> 285\u001b[0m smile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smile(options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    286\u001b[0m smile\u001b[38;5;241m.\u001b[39mexternal_sink_set_callback_ex(\n\u001b[0;32m    287\u001b[0m     config\u001b[38;5;241m.\u001b[39mEXTERNAL_OUTPUT_COMPONENT, Smile\u001b[38;5;241m.\u001b[39m_sink_callback(y, starts, ends)\n\u001b[0;32m    288\u001b[0m )\n\u001b[0;32m    289\u001b[0m smile\u001b[38;5;241m.\u001b[39mexternal_audio_source_write_data(\n\u001b[0;32m    290\u001b[0m     config\u001b[38;5;241m.\u001b[39mEXTERNAL_SOURCE_COMPONENT, \u001b[38;5;28mbytes\u001b[39m(x)\n\u001b[0;32m    291\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\opensmile\\core\\smile.py:413\u001b[0m, in \u001b[0;36mSmile._smile\u001b[1;34m(self, options)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Set up smile instance.\"\"\"\u001b[39;00m\n\u001b[0;32m    412\u001b[0m smile \u001b[38;5;241m=\u001b[39m OpenSMILE()\n\u001b[1;32m--> 413\u001b[0m smile\u001b[38;5;241m.\u001b[39minitialize(\n\u001b[0;32m    414\u001b[0m     config_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_path,\n\u001b[0;32m    415\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    416\u001b[0m     loglevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglevel,\n\u001b[0;32m    417\u001b[0m     log_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogfile,\n\u001b[0;32m    418\u001b[0m     debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    419\u001b[0m )\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m smile\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\opensmile\\core\\lib.py:325\u001b[0m, in \u001b[0;36mOpenSMILE.initialize\u001b[1;34m(self, config_file, options, loglevel, debug, console_output, log_file)\u001b[0m\n\u001b[0;32m    322\u001b[0m options_char_arr \u001b[38;5;241m=\u001b[39m c_char_p_arr(options_flat)\n\u001b[0;32m    323\u001b[0m log_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(log_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m log_file \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_smile_result(\n\u001b[1;32m--> 325\u001b[0m     smileapi\u001b[38;5;241m.\u001b[39msmile_initialize(\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smileobj,\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28mbytes\u001b[39m(config_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mlen\u001b[39m(options),\n\u001b[0;32m    329\u001b[0m         options_char_arr,\n\u001b[0;32m    330\u001b[0m         loglevel,\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;28mint\u001b[39m(debug),\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mint\u001b[39m(console_output),\n\u001b[0;32m    333\u001b[0m         log_file,\n\u001b[0;32m    334\u001b[0m     )\n\u001b[0;32m    335\u001b[0m )\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callbacks \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LDA pour emotion + sentiment\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import opensmile\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Chemin du dossier principal\n",
    "dataset_path = \"dataset_clean\"\n",
    "\n",
    "# Dossiers à traiter\n",
    "folders = [\"dev\", \"train\", \"test\"]\n",
    "\n",
    "# Pour chaque dossier\n",
    "for folder in folders:\n",
    "    print(f\"\\nTraitement du dossier {folder}...\")\n",
    "    \n",
    "    # Charger le CSV filtré avec les labels\n",
    "    csv_path = os.path.join(dataset_path, folder, f\"filtered_{folder}_sent_emo.csv\")\n",
    "    try:\n",
    "        labels_df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture de {csv_path} : {e}\")\n",
    "        continue\n",
    "\n",
    "    # Dossier des audios\n",
    "    audios_dir = os.path.join(dataset_path, folder, \"audios\")\n",
    "    if not os.path.exists(audios_dir):\n",
    "        print(f\"Le dossier des audios n'existe pas : {audios_dir}\")\n",
    "        continue\n",
    "\n",
    "    features_list = []\n",
    "\n",
    "    # Initialiser opensmile (ici avec ComParE_2016 et niveau Functionals)\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals\n",
    "    )\n",
    "    \n",
    "    file_count = 0\n",
    "    \n",
    "    # Parcourir les fichiers audio\n",
    "    for file in os.listdir(audios_dir):\n",
    "        if file.lower().endswith(\".wav\"):\n",
    "            audio_path = os.path.join(audios_dir, file)\n",
    "            \n",
    "            # Extraire dialogue_id et utterance_id à partir du nom de fichier\n",
    "            match = re.match(r\"dia(\\d+)_utt(\\d+)\", file)\n",
    "            if not match:\n",
    "                print(f\"Nom de fichier non conforme : {file}\")\n",
    "                continue\n",
    "            dialogue_id = int(match.group(1))\n",
    "            utterance_id = int(match.group(2))\n",
    "            \n",
    "            try:\n",
    "                # Extraction des caractéristiques avec opensmile\n",
    "                features_df = smile.process_file(audio_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de l'extraction pour {file} : {e}\")\n",
    "                continue\n",
    "\n",
    "            # On récupère la première (et unique) ligne des features extraites\n",
    "            feat_dict = features_df.iloc[0].to_dict()\n",
    "            # print(f\"Nombre de caractéristiques extraites : {len(feat_dict)}\") #la raison pour laquelle on utilise lda\n",
    "            feat_dict[\"Dialogue_ID\"] = dialogue_id\n",
    "            feat_dict[\"Utterance_ID\"] = utterance_id\n",
    "            \n",
    "            # Récupérer les labels correspondant à ce fichier\n",
    "            label_row = labels_df[\n",
    "                (labels_df[\"Dialogue_ID\"] == dialogue_id) &\n",
    "                (labels_df[\"Utterance_ID\"] == utterance_id)\n",
    "            ].iloc[0]  # On prend directement la première ligne correspondante\n",
    "\n",
    "            feat_dict[\"Emotion\"] = label_row[\"Emotion\"]\n",
    "            feat_dict[\"Sentiment\"] = label_row[\"Sentiment\"]\n",
    "            \n",
    "            features_list.append(feat_dict)\n",
    "            \n",
    "            # Incrémenter le compteur\n",
    "            file_count += 1\n",
    "\n",
    "            # Afficher tous les 100 fichiers traités\n",
    "            if file_count % 100 == 0:\n",
    "                print(f\"Progression : {file_count} fichiers traités\")\n",
    "    \n",
    "    # Créer un DataFrame avec toutes les caractéristiques\n",
    "    if not features_list:\n",
    "        print(f\"Aucun fichier audio traité dans {audios_dir}\")\n",
    "        continue\n",
    "    features_all = pd.DataFrame(features_list)\n",
    "    \n",
    "    # Créer une colonne \"Label\" qui combine Emotion et Sentiment si possible\n",
    "    def combine_labels(row):\n",
    "        if pd.notnull(row[\"Emotion\"]) and pd.notnull(row[\"Sentiment\"]):\n",
    "            return f\"{row['Emotion']}_{row['Sentiment']}\"\n",
    "        else:\n",
    "            return row[\"Emotion\"]\n",
    "    \n",
    "    features_all[\"Label\"] = features_all.apply(combine_labels, axis=1)\n",
    "    \n",
    "    # Sélectionner les colonnes de features (exclure les colonnes non-numériques et les labels)\n",
    "    exclude_cols = [\"Dialogue_ID\", \"Utterance_ID\", \"Emotion\", \"Sentiment\", \"Label\"]\n",
    "    feature_cols = [col for col in features_all.columns if col not in exclude_cols]\n",
    "    \n",
    "    X = features_all[feature_cols].values\n",
    "    y = features_all[\"Label\"].values\n",
    "\n",
    "    # Appliquer LDA si plusieurs classes sont présentes (LDA est supervisé)\n",
    "    unique_labels = set(y)\n",
    "    if len(unique_labels) > 1:\n",
    "        n_components = min(len(unique_labels) - 1, X.shape[1])\n",
    "        lda = LDA(n_components=n_components)\n",
    "        try:\n",
    "            X_reduced = lda.fit_transform(X, y)\n",
    "            # Ajouter les composantes réduites au DataFrame\n",
    "            for i in range(X_reduced.shape[1]):\n",
    "                features_all[f\"LDA_{i+1}\"] = X_reduced[:, i]\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de LDA pour le dossier {folder} : {e}\")\n",
    "    else:\n",
    "        print(f\"Pas assez de classes pour appliquer LDA dans le dossier {folder}.\")\n",
    "\n",
    "    # Enregistrer le DataFrame avec les caractéristiques dans un CSV\n",
    "    output_csv = os.path.join(dataset_path, folder, f\"features_{folder}.csv\")\n",
    "    features_all.to_csv(output_csv, index=False)\n",
    "    print(f\"Fichier des caractéristiques sauvegardé : {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed9bf73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traitement du dossier dev...\n",
      "Progression : 100 fichiers traités\n",
      "Progression : 200 fichiers traités\n",
      "Progression : 300 fichiers traités\n",
      "Progression : 400 fichiers traités\n",
      "Progression : 500 fichiers traités\n",
      "Progression : 600 fichiers traités\n",
      "Progression : 700 fichiers traités\n",
      "Progression : 800 fichiers traités\n",
      "Progression : 900 fichiers traités\n",
      "Progression : 1000 fichiers traités\n",
      "Progression : 1100 fichiers traités\n",
      "Fichier des caractéristiques sauvegardé : dataset_clean\\dev\\features_dev_emotion.csv\n",
      "\n",
      "Traitement du dossier train...\n",
      "Progression : 100 fichiers traités\n",
      "Progression : 200 fichiers traités\n",
      "Progression : 300 fichiers traités\n",
      "Progression : 400 fichiers traités\n",
      "Progression : 500 fichiers traités\n",
      "Progression : 600 fichiers traités\n",
      "Progression : 700 fichiers traités\n",
      "Progression : 800 fichiers traités\n",
      "Progression : 900 fichiers traités\n",
      "Progression : 1000 fichiers traités\n",
      "Progression : 1100 fichiers traités\n",
      "Progression : 1200 fichiers traités\n",
      "Progression : 1300 fichiers traités\n",
      "Progression : 1400 fichiers traités\n",
      "Progression : 1500 fichiers traités\n",
      "Progression : 1600 fichiers traités\n",
      "Progression : 1700 fichiers traités\n",
      "Progression : 1800 fichiers traités\n",
      "Progression : 1900 fichiers traités\n",
      "Progression : 2000 fichiers traités\n",
      "Progression : 2100 fichiers traités\n",
      "Progression : 2200 fichiers traités\n",
      "Progression : 2300 fichiers traités\n",
      "Progression : 2400 fichiers traités\n",
      "Progression : 2500 fichiers traités\n",
      "Progression : 2600 fichiers traités\n",
      "Progression : 2700 fichiers traités\n",
      "Progression : 2800 fichiers traités\n",
      "Progression : 2900 fichiers traités\n",
      "Progression : 3000 fichiers traités\n",
      "Progression : 3100 fichiers traités\n",
      "Progression : 3200 fichiers traités\n",
      "Progression : 3300 fichiers traités\n",
      "Progression : 3400 fichiers traités\n",
      "Progression : 3500 fichiers traités\n",
      "Progression : 3600 fichiers traités\n",
      "Progression : 3700 fichiers traités\n",
      "Progression : 3800 fichiers traités\n",
      "Progression : 3900 fichiers traités\n",
      "Progression : 4000 fichiers traités\n",
      "Progression : 4100 fichiers traités\n",
      "Progression : 4200 fichiers traités\n",
      "Progression : 4300 fichiers traités\n",
      "Progression : 4400 fichiers traités\n",
      "Progression : 4500 fichiers traités\n",
      "Progression : 4600 fichiers traités\n",
      "Progression : 4700 fichiers traités\n",
      "Progression : 4800 fichiers traités\n",
      "Progression : 4900 fichiers traités\n",
      "Progression : 5000 fichiers traités\n",
      "Progression : 5100 fichiers traités\n",
      "Progression : 5200 fichiers traités\n",
      "Progression : 5300 fichiers traités\n",
      "Progression : 5400 fichiers traités\n",
      "Progression : 5500 fichiers traités\n",
      "Progression : 5600 fichiers traités\n",
      "Progression : 5700 fichiers traités\n",
      "Progression : 5800 fichiers traités\n",
      "Progression : 5900 fichiers traités\n",
      "Progression : 6000 fichiers traités\n",
      "Progression : 6100 fichiers traités\n",
      "Progression : 6200 fichiers traités\n",
      "Progression : 6300 fichiers traités\n",
      "Progression : 6400 fichiers traités\n",
      "Progression : 6500 fichiers traités\n",
      "Progression : 6600 fichiers traités\n",
      "Progression : 6700 fichiers traités\n",
      "Progression : 6800 fichiers traités\n",
      "Progression : 6900 fichiers traités\n",
      "Progression : 7000 fichiers traités\n",
      "Progression : 7100 fichiers traités\n",
      "Progression : 7200 fichiers traités\n",
      "Progression : 7300 fichiers traités\n",
      "Progression : 7400 fichiers traités\n",
      "Progression : 7500 fichiers traités\n",
      "Progression : 7600 fichiers traités\n",
      "Progression : 7700 fichiers traités\n",
      "Progression : 7800 fichiers traités\n",
      "Progression : 7900 fichiers traités\n",
      "Progression : 8000 fichiers traités\n",
      "Progression : 8100 fichiers traités\n",
      "Progression : 8200 fichiers traités\n",
      "Progression : 8300 fichiers traités\n",
      "Progression : 8400 fichiers traités\n",
      "Progression : 8500 fichiers traités\n",
      "Progression : 8600 fichiers traités\n",
      "Progression : 8700 fichiers traités\n",
      "Progression : 8800 fichiers traités\n",
      "Progression : 8900 fichiers traités\n",
      "Progression : 9000 fichiers traités\n",
      "Progression : 9100 fichiers traités\n",
      "Progression : 9200 fichiers traités\n",
      "Progression : 9300 fichiers traités\n",
      "Progression : 9400 fichiers traités\n",
      "Progression : 9500 fichiers traités\n",
      "Progression : 9600 fichiers traités\n",
      "Progression : 9700 fichiers traités\n",
      "Progression : 9800 fichiers traités\n",
      "Progression : 9900 fichiers traités\n",
      "Fichier des caractéristiques sauvegardé : dataset_clean\\train\\features_train_emotion.csv\n",
      "\n",
      "Traitement du dossier test...\n",
      "Progression : 100 fichiers traités\n",
      "Progression : 200 fichiers traités\n",
      "Progression : 300 fichiers traités\n",
      "Progression : 400 fichiers traités\n",
      "Progression : 500 fichiers traités\n",
      "Progression : 600 fichiers traités\n",
      "Progression : 700 fichiers traités\n",
      "Progression : 800 fichiers traités\n",
      "Progression : 900 fichiers traités\n",
      "Progression : 1000 fichiers traités\n",
      "Progression : 1100 fichiers traités\n",
      "Progression : 1200 fichiers traités\n",
      "Progression : 1300 fichiers traités\n",
      "Progression : 1400 fichiers traités\n",
      "Progression : 1500 fichiers traités\n",
      "Progression : 1600 fichiers traités\n",
      "Progression : 1700 fichiers traités\n",
      "Progression : 1800 fichiers traités\n",
      "Progression : 1900 fichiers traités\n",
      "Progression : 2000 fichiers traités\n",
      "Progression : 2100 fichiers traités\n",
      "Progression : 2200 fichiers traités\n",
      "Progression : 2300 fichiers traités\n",
      "Progression : 2400 fichiers traités\n",
      "Progression : 2500 fichiers traités\n",
      "Progression : 2600 fichiers traités\n",
      "Fichier des caractéristiques sauvegardé : dataset_clean\\test\\features_test_emotion.csv\n"
     ]
    }
   ],
   "source": [
    "#LDA pour emotion only\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import opensmile\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Chemin du dossier principal\n",
    "dataset_path = \"dataset_clean\"\n",
    "\n",
    "# Dossiers à traiter\n",
    "folders = [\"dev\", \"train\", \"test\"]\n",
    "\n",
    "# Pour chaque dossier\n",
    "for folder in folders:\n",
    "    print(f\"\\nTraitement du dossier {folder}...\")\n",
    "    \n",
    "    # Charger le CSV filtré avec les labels\n",
    "    csv_path = os.path.join(dataset_path, folder, f\"filtered_{folder}_sent_emo.csv\")\n",
    "    try:\n",
    "        labels_df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture de {csv_path} : {e}\")\n",
    "        continue\n",
    "\n",
    "    # Dossier des audios\n",
    "    audios_dir = os.path.join(dataset_path, folder, \"audios\")\n",
    "    if not os.path.exists(audios_dir):\n",
    "        print(f\"Le dossier des audios n'existe pas : {audios_dir}\")\n",
    "        continue\n",
    "\n",
    "    features_list = []\n",
    "\n",
    "    # Initialiser opensmile (ici avec ComParE_2016 et niveau Functionals)\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals\n",
    "    )\n",
    "    \n",
    "    file_count = 0\n",
    "    \n",
    "    # Parcourir les fichiers audio\n",
    "    for file in os.listdir(audios_dir):\n",
    "        if file.lower().endswith(\".wav\"):\n",
    "            audio_path = os.path.join(audios_dir, file)\n",
    "            \n",
    "            # Extraire dialogue_id et utterance_id à partir du nom de fichier\n",
    "            match = re.match(r\"dia(\\d+)_utt(\\d+)\", file)\n",
    "            if not match:\n",
    "                print(f\"Nom de fichier non conforme : {file}\")\n",
    "                continue\n",
    "            dialogue_id = int(match.group(1))\n",
    "            utterance_id = int(match.group(2))\n",
    "            \n",
    "            try:\n",
    "                # Extraction des caractéristiques avec opensmile\n",
    "                features_df = smile.process_file(audio_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de l'extraction pour {file} : {e}\")\n",
    "                continue\n",
    "\n",
    "            # On récupère la première (et unique) ligne des features extraites\n",
    "            feat_dict = features_df.iloc[0].to_dict()\n",
    "            feat_dict[\"Dialogue_ID\"] = dialogue_id\n",
    "            feat_dict[\"Utterance_ID\"] = utterance_id\n",
    "            \n",
    "            # Récupérer le label d'Emotion correspondant à ce fichier\n",
    "            label_row = labels_df[\n",
    "                (labels_df[\"Dialogue_ID\"] == dialogue_id) &\n",
    "                (labels_df[\"Utterance_ID\"] == utterance_id)\n",
    "            ].iloc[0]  # On prend directement la première ligne correspondante\n",
    "\n",
    "            feat_dict[\"Emotion\"] = label_row[\"Emotion\"]\n",
    "            \n",
    "            features_list.append(feat_dict)\n",
    "            \n",
    "            # Incrémenter le compteur\n",
    "            file_count += 1\n",
    "\n",
    "            # Afficher tous les 100 fichiers traités\n",
    "            if file_count % 100 == 0:\n",
    "                print(f\"Progression : {file_count} fichiers traités\")\n",
    "    \n",
    "    # Créer un DataFrame avec toutes les caractéristiques\n",
    "    if not features_list:\n",
    "        print(f\"Aucun fichier audio traité dans {audios_dir}\")\n",
    "        continue\n",
    "    features_all = pd.DataFrame(features_list)\n",
    "    \n",
    "    # Sélectionner les colonnes de features (exclure les colonnes non-numériques et le label Emotion)\n",
    "    exclude_cols = [\"Dialogue_ID\", \"Utterance_ID\", \"Emotion\"]\n",
    "    feature_cols = [col for col in features_all.columns if col not in exclude_cols]\n",
    "    \n",
    "    X = features_all[feature_cols].values\n",
    "    y = features_all[\"Emotion\"].values  # On utilise uniquement Emotion comme cible\n",
    "\n",
    "    # Appliquer LDA si plusieurs émotions sont présentes (LDA est supervisé)\n",
    "    unique_emotions = set(y)\n",
    "    if len(unique_emotions) > 1:\n",
    "        n_components = min(len(unique_emotions) - 1, X.shape[1])  # Le nombre de composantes est min(émotions - 1, caractéristiques)\n",
    "        lda = LDA(n_components=n_components)\n",
    "        try:\n",
    "            X_reduced = lda.fit_transform(X, y)\n",
    "            # Ajouter les composantes réduites au DataFrame\n",
    "            for i in range(X_reduced.shape[1]):\n",
    "                features_all[f\"LDA_{i+1}\"] = X_reduced[:, i]\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de LDA pour le dossier {folder} : {e}\")\n",
    "    else:\n",
    "        print(f\"Pas assez de classes pour appliquer LDA dans le dossier {folder}.\")\n",
    "\n",
    "    # Filtrer les colonnes pour ne garder que les caractéristiques (et Emotion)\n",
    "    columns_to_keep = [\"Emotion\"] + [f\"LDA_{i+1}\" for i in range(X_reduced.shape[1])]\n",
    "    features_all = features_all[columns_to_keep]\n",
    "\n",
    "    # Enregistrer le DataFrame avec les caractéristiques dans un CSV\n",
    "    output_csv = os.path.join(dataset_path, folder, f\"features_{folder}_emotion.csv\")\n",
    "    features_all.to_csv(output_csv, index=False)\n",
    "    print(f\"Fichier des caractéristiques sauvegardé : {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb0be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA pour sentiment only \n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import opensmile\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Chemin du dossier principal\n",
    "dataset_path = \"dataset_clean\"\n",
    "\n",
    "# Dossiers à traiter\n",
    "folders = [\"train\", \"dev\", \"test\"]\n",
    "\n",
    "# Pour chaque dossier\n",
    "for folder in folders:\n",
    "    print(f\"\\nTraitement du dossier {folder}...\")\n",
    "    \n",
    "    # Charger le CSV filtré avec les labels\n",
    "    csv_path = os.path.join(dataset_path, folder, f\"filtered_{folder}_sent_emo.csv\")\n",
    "    try:\n",
    "        labels_df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture de {csv_path} : {e}\")\n",
    "        continue\n",
    "\n",
    "    # Dossier des audios\n",
    "    audios_dir = os.path.join(dataset_path, folder, \"audios\")\n",
    "    if not os.path.exists(audios_dir):\n",
    "        print(f\"Le dossier des audios n'existe pas : {audios_dir}\")\n",
    "        continue\n",
    "\n",
    "    features_list = []\n",
    "\n",
    "    # Initialiser opensmile (ici avec ComParE_2016 et niveau Functionals)\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals\n",
    "    )\n",
    "    \n",
    "    file_count = 0\n",
    "    \n",
    "    # Parcourir les fichiers audio\n",
    "    for file in os.listdir(audios_dir):\n",
    "        if file.lower().endswith(\".wav\"):\n",
    "            audio_path = os.path.join(audios_dir, file)\n",
    "            \n",
    "            # Extraire dialogue_id et utterance_id à partir du nom de fichier\n",
    "            match = re.match(r\"dia(\\d+)_utt(\\d+)\", file)\n",
    "            if not match:\n",
    "                print(f\"Nom de fichier non conforme : {file}\")\n",
    "                continue\n",
    "            dialogue_id = int(match.group(1))\n",
    "            utterance_id = int(match.group(2))\n",
    "            \n",
    "            try:\n",
    "                # Extraction des caractéristiques avec opensmile\n",
    "                features_df = smile.process_file(audio_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de l'extraction pour {file} : {e}\")\n",
    "                continue\n",
    "\n",
    "            # On récupère la première (et unique) ligne des features extraites\n",
    "            feat_dict = features_df.iloc[0].to_dict()\n",
    "            feat_dict[\"Dialogue_ID\"] = dialogue_id\n",
    "            feat_dict[\"Utterance_ID\"] = utterance_id\n",
    "            \n",
    "            # Récupérer le label de Sentiment correspondant à ce fichier\n",
    "            label_row = labels_df[\n",
    "                (labels_df[\"Dialogue_ID\"] == dialogue_id) &\n",
    "                (labels_df[\"Utterance_ID\"] == utterance_id)\n",
    "            ].iloc[0]  # On prend directement la première ligne correspondante\n",
    "\n",
    "            feat_dict[\"Sentiment\"] = label_row[\"Sentiment\"]\n",
    "            \n",
    "            features_list.append(feat_dict)\n",
    "            \n",
    "            # Incrémenter le compteur\n",
    "            file_count += 1\n",
    "\n",
    "            # Afficher tous les 100 fichiers traités\n",
    "            if file_count % 100 == 0:\n",
    "                print(f\"Progression : {file_count} fichiers traités\")\n",
    "    \n",
    "    # Créer un DataFrame avec toutes les caractéristiques\n",
    "    if not features_list:\n",
    "        print(f\"Aucun fichier audio traité dans {audios_dir}\")\n",
    "        continue\n",
    "    features_all = pd.DataFrame(features_list)\n",
    "    \n",
    "    # Sélectionner les colonnes de features (exclure les colonnes non-numériques et le label Sentiment)\n",
    "    exclude_cols = [\"Dialogue_ID\", \"Utterance_ID\", \"Sentiment\"]\n",
    "    feature_cols = [col for col in features_all.columns if col not in exclude_cols]\n",
    "    \n",
    "    X = features_all[feature_cols].values\n",
    "    y = features_all[\"Sentiment\"].values  # On utilise uniquement Sentiment comme cible\n",
    "\n",
    "    # Appliquer LDA si plusieurs sentiments sont présents (LDA est supervisé)\n",
    "    unique_sentiments = set(y)\n",
    "    if len(unique_sentiments) > 1:\n",
    "        n_components = min(len(unique_sentiments) - 1, X.shape[1])  # Le nombre de composantes est min(sentiments - 1, caractéristiques)\n",
    "        lda = LDA(n_components=n_components)\n",
    "        try:\n",
    "            X_reduced = lda.fit_transform(X, y)\n",
    "            # Ajouter les composantes réduites au DataFrame\n",
    "            for i in range(X_reduced.shape[1]):\n",
    "                features_all[f\"LDA_{i+1}\"] = X_reduced[:, i]\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de LDA pour le dossier {folder} : {e}\")\n",
    "    else:\n",
    "        print(f\"Pas assez de classes pour appliquer LDA dans le dossier {folder}.\")\n",
    "\n",
    "    # Enregistrer le DataFrame avec les caractéristiques dans un CSV\n",
    "    output_csv = os.path.join(dataset_path, folder, f\"features_{folder}_sentiment.csv\")\n",
    "    features_all.to_csv(output_csv, index=False)\n",
    "    print(f\"Fichier des caractéristiques sauvegardé : {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "967432e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression : 100 fichiers traités\n",
      "Progression : 200 fichiers traités\n",
      "Progression : 300 fichiers traités\n",
      "Progression : 400 fichiers traités\n",
      "Progression : 500 fichiers traités\n",
      "Progression : 600 fichiers traités\n",
      "Progression : 700 fichiers traités\n",
      "Progression : 800 fichiers traités\n",
      "Progression : 900 fichiers traités\n",
      "Progression : 1000 fichiers traités\n",
      "Progression : 1100 fichiers traités\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision : 0.4324\n",
      "\n",
      "Rapport de classification :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        30\n",
      "     disgust       0.00      0.00      0.00         3\n",
      "        fear       0.00      0.00      0.00         7\n",
      "         joy       0.00      0.00      0.00        28\n",
      "     neutral       0.44      0.97      0.60        97\n",
      "     sadness       0.00      0.00      0.00        28\n",
      "    surprise       0.67      0.07      0.12        29\n",
      "\n",
      "    accuracy                           0.43       222\n",
      "   macro avg       0.16      0.15      0.10       222\n",
      "weighted avg       0.28      0.43      0.28       222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import opensmile\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chemin du dossier principal\n",
    "dataset_path = \"dataset_clean\"\n",
    "\n",
    "# Dossier à traiter (ici 'dev' uniquement pour tester la précision)\n",
    "folder = \"dev\"\n",
    "\n",
    "# Charger le CSV filtré avec les labels\n",
    "csv_path = os.path.join(dataset_path, folder, f\"filtered_{folder}_sent_emo.csv\")\n",
    "try:\n",
    "    labels_df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la lecture de {csv_path} : {e}\")\n",
    "\n",
    "# Dossier des audios\n",
    "audios_dir = os.path.join(dataset_path, folder, \"audios\")\n",
    "if not os.path.exists(audios_dir):\n",
    "    print(f\"Le dossier des audios n'existe pas : {audios_dir}\")\n",
    "\n",
    "features_list = []\n",
    "\n",
    "# Initialiser opensmile (ici avec ComParE_2016 et niveau Functionals)\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals\n",
    ")\n",
    "\n",
    "file_count = 0\n",
    "\n",
    "# Parcourir les fichiers audio\n",
    "for file in os.listdir(audios_dir):\n",
    "    if file.lower().endswith(\".wav\"):\n",
    "        audio_path = os.path.join(audios_dir, file)\n",
    "        \n",
    "        # Extraire dialogue_id et utterance_id à partir du nom de fichier\n",
    "        match = re.match(r\"dia(\\d+)_utt(\\d+)\", file)\n",
    "        if not match:\n",
    "            print(f\"Nom de fichier non conforme : {file}\")\n",
    "            continue\n",
    "        dialogue_id = int(match.group(1))\n",
    "        utterance_id = int(match.group(2))\n",
    "        \n",
    "        try:\n",
    "            # Extraction des caractéristiques avec opensmile\n",
    "            features_df = smile.process_file(audio_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'extraction pour {file} : {e}\")\n",
    "            continue\n",
    "\n",
    "        # On récupère la première (et unique) ligne des features extraites\n",
    "        feat_dict = features_df.iloc[0].to_dict()\n",
    "        feat_dict[\"Dialogue_ID\"] = dialogue_id\n",
    "        feat_dict[\"Utterance_ID\"] = utterance_id\n",
    "        \n",
    "        # Récupérer la label d'Emotion correspondant à ce fichier\n",
    "        label_row = labels_df[\n",
    "            (labels_df[\"Dialogue_ID\"] == dialogue_id) & \n",
    "            (labels_df[\"Utterance_ID\"] == utterance_id)\n",
    "        ].iloc[0]  # On prend directement la première ligne correspondante\n",
    "\n",
    "        feat_dict[\"Emotion\"] = label_row[\"Emotion\"]\n",
    "        \n",
    "        features_list.append(feat_dict)\n",
    "        \n",
    "        # Incrémenter le compteur\n",
    "        file_count += 1\n",
    "\n",
    "        # Afficher tous les 100 fichiers traités\n",
    "        if file_count % 100 == 0:\n",
    "            print(f\"Progression : {file_count} fichiers traités\")\n",
    "\n",
    "# Créer un DataFrame avec toutes les caractéristiques\n",
    "if not features_list:\n",
    "    print(f\"Aucun fichier audio traité dans {audios_dir}\")\n",
    "\n",
    "features_all = pd.DataFrame(features_list)\n",
    "\n",
    "# Sélectionner les colonnes de features (exclure les colonnes non-numériques et le label Emotion)\n",
    "exclude_cols = [\"Dialogue_ID\", \"Utterance_ID\", \"Emotion\"]\n",
    "feature_cols = [col for col in features_all.columns if col not in exclude_cols]\n",
    "\n",
    "X = features_all[feature_cols].values\n",
    "y = features_all[\"Emotion\"].values  # On utilise uniquement Emotion comme cible\n",
    "\n",
    "# 1. Appliquer PCA pour réduire la dimensionnalité\n",
    "pca = PCA(n_components=50)  # Tu peux ajuster le nombre de composantes\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# 2. Afficher la variance expliquée cumulée par les composantes principales\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "# Tracer la courbe de variance expliquée\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance.cumsum(), marker='o')\n",
    "plt.xlabel(\"Nombre de composantes\")\n",
    "plt.ylabel(\"Variance expliquée cumulée\")\n",
    "plt.title(\"Variance expliquée par les composantes principales\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 3. Diviser les données en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Entraîner un modèle de classification (ici RandomForestClassifier)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Prédiction et évaluation sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Précision : {accuracy:.4f}\")\n",
    "print(\"\\nRapport de classification :\\n\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c41dac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traitement du dossier dev...\n",
      "Progression : 100 fichiers traités\n",
      "Progression : 200 fichiers traités\n",
      "Progression : 300 fichiers traités\n",
      "Progression : 400 fichiers traités\n",
      "Progression : 500 fichiers traités\n",
      "Progression : 600 fichiers traités\n",
      "Progression : 700 fichiers traités\n",
      "Progression : 800 fichiers traités\n",
      "Progression : 900 fichiers traités\n",
      "Progression : 1000 fichiers traités\n",
      "Progression : 1100 fichiers traités\n",
      "Fichier des caractéristiques PCA sauvegardé : dataset_clean\\dev\\features_dev_pca.csv\n",
      "\n",
      "Traitement du dossier train...\n",
      "Progression : 100 fichiers traités\n",
      "Progression : 200 fichiers traités\n",
      "Progression : 300 fichiers traités\n",
      "Progression : 400 fichiers traités\n",
      "Progression : 500 fichiers traités\n",
      "Progression : 600 fichiers traités\n",
      "Progression : 700 fichiers traités\n",
      "Progression : 800 fichiers traités\n",
      "Progression : 900 fichiers traités\n",
      "Progression : 1000 fichiers traités\n",
      "Progression : 1100 fichiers traités\n",
      "Progression : 1200 fichiers traités\n",
      "Progression : 1300 fichiers traités\n",
      "Progression : 1400 fichiers traités\n",
      "Progression : 1500 fichiers traités\n",
      "Progression : 1600 fichiers traités\n",
      "Progression : 1700 fichiers traités\n",
      "Progression : 1800 fichiers traités\n",
      "Progression : 1900 fichiers traités\n",
      "Progression : 2000 fichiers traités\n",
      "Progression : 2100 fichiers traités\n",
      "Progression : 2200 fichiers traités\n",
      "Progression : 2300 fichiers traités\n",
      "Progression : 2400 fichiers traités\n",
      "Progression : 2500 fichiers traités\n",
      "Progression : 2600 fichiers traités\n",
      "Progression : 2700 fichiers traités\n",
      "Progression : 2800 fichiers traités\n",
      "Progression : 2900 fichiers traités\n",
      "Progression : 3000 fichiers traités\n",
      "Progression : 3100 fichiers traités\n",
      "Progression : 3200 fichiers traités\n",
      "Progression : 3300 fichiers traités\n",
      "Progression : 3400 fichiers traités\n",
      "Progression : 3500 fichiers traités\n",
      "Progression : 3600 fichiers traités\n",
      "Progression : 3700 fichiers traités\n",
      "Progression : 3800 fichiers traités\n",
      "Progression : 3900 fichiers traités\n",
      "Progression : 4000 fichiers traités\n",
      "Progression : 4100 fichiers traités\n",
      "Progression : 4200 fichiers traités\n",
      "Progression : 4300 fichiers traités\n",
      "Progression : 4400 fichiers traités\n",
      "Progression : 4500 fichiers traités\n",
      "Progression : 4600 fichiers traités\n",
      "Progression : 4700 fichiers traités\n",
      "Progression : 4800 fichiers traités\n",
      "Progression : 4900 fichiers traités\n",
      "Progression : 5000 fichiers traités\n",
      "Progression : 5100 fichiers traités\n",
      "Progression : 5200 fichiers traités\n",
      "Progression : 5300 fichiers traités\n",
      "Progression : 5400 fichiers traités\n",
      "Progression : 5500 fichiers traités\n",
      "Progression : 5600 fichiers traités\n",
      "Progression : 5700 fichiers traités\n",
      "Progression : 5800 fichiers traités\n",
      "Progression : 5900 fichiers traités\n",
      "Progression : 6000 fichiers traités\n",
      "Progression : 6100 fichiers traités\n",
      "Progression : 6200 fichiers traités\n",
      "Progression : 6300 fichiers traités\n",
      "Progression : 6400 fichiers traités\n",
      "Progression : 6500 fichiers traités\n",
      "Progression : 6600 fichiers traités\n",
      "Progression : 6700 fichiers traités\n",
      "Progression : 6800 fichiers traités\n",
      "Progression : 6900 fichiers traités\n",
      "Progression : 7000 fichiers traités\n",
      "Progression : 7100 fichiers traités\n",
      "Progression : 7200 fichiers traités\n",
      "Progression : 7300 fichiers traités\n",
      "Progression : 7400 fichiers traités\n",
      "Progression : 7500 fichiers traités\n",
      "Progression : 7600 fichiers traités\n",
      "Progression : 7700 fichiers traités\n",
      "Progression : 7800 fichiers traités\n",
      "Progression : 7900 fichiers traités\n",
      "Progression : 8000 fichiers traités\n",
      "Progression : 8100 fichiers traités\n",
      "Progression : 8200 fichiers traités\n",
      "Progression : 8300 fichiers traités\n",
      "Progression : 8400 fichiers traités\n",
      "Progression : 8500 fichiers traités\n",
      "Progression : 8600 fichiers traités\n",
      "Progression : 8700 fichiers traités\n",
      "Progression : 8800 fichiers traités\n",
      "Progression : 8900 fichiers traités\n",
      "Progression : 9000 fichiers traités\n",
      "Progression : 9100 fichiers traités\n",
      "Progression : 9200 fichiers traités\n",
      "Progression : 9300 fichiers traités\n",
      "Progression : 9400 fichiers traités\n",
      "Progression : 9500 fichiers traités\n",
      "Progression : 9600 fichiers traités\n",
      "Progression : 9700 fichiers traités\n",
      "Progression : 9800 fichiers traités\n",
      "Progression : 9900 fichiers traités\n",
      "Fichier des caractéristiques PCA sauvegardé : dataset_clean\\train\\features_train_pca.csv\n",
      "\n",
      "Traitement du dossier test...\n",
      "Progression : 100 fichiers traités\n",
      "Progression : 200 fichiers traités\n",
      "Progression : 300 fichiers traités\n",
      "Progression : 400 fichiers traités\n",
      "Progression : 500 fichiers traités\n",
      "Progression : 600 fichiers traités\n",
      "Progression : 700 fichiers traités\n",
      "Progression : 800 fichiers traités\n",
      "Progression : 900 fichiers traités\n",
      "Progression : 1000 fichiers traités\n",
      "Progression : 1100 fichiers traités\n",
      "Progression : 1200 fichiers traités\n",
      "Progression : 1300 fichiers traités\n",
      "Progression : 1400 fichiers traités\n",
      "Progression : 1500 fichiers traités\n",
      "Progression : 1600 fichiers traités\n",
      "Progression : 1700 fichiers traités\n",
      "Progression : 1800 fichiers traités\n",
      "Progression : 1900 fichiers traités\n",
      "Progression : 2000 fichiers traités\n",
      "Progression : 2100 fichiers traités\n",
      "Progression : 2200 fichiers traités\n",
      "Progression : 2300 fichiers traités\n",
      "Progression : 2400 fichiers traités\n",
      "Progression : 2500 fichiers traités\n",
      "Progression : 2600 fichiers traités\n",
      "Fichier des caractéristiques PCA sauvegardé : dataset_clean\\test\\features_test_pca.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import opensmile\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Chemin du dossier principal\n",
    "dataset_path = \"dataset_clean\"\n",
    "\n",
    "# Dossiers à traiter\n",
    "folders = [\"dev\", \"train\", \"test\"]\n",
    "\n",
    "# Pour chaque dossier\n",
    "for folder in folders:\n",
    "    print(f\"\\nTraitement du dossier {folder}...\")\n",
    "    \n",
    "    # Charger le CSV filtré avec les labels\n",
    "    csv_path = os.path.join(dataset_path, folder, f\"filtered_{folder}_sent_emo.csv\")\n",
    "    try:\n",
    "        labels_df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture de {csv_path} : {e}\")\n",
    "        continue\n",
    "\n",
    "    # Dossier des audios\n",
    "    audios_dir = os.path.join(dataset_path, folder, \"audios\")\n",
    "    if not os.path.exists(audios_dir):\n",
    "        print(f\"Le dossier des audios n'existe pas : {audios_dir}\")\n",
    "        continue\n",
    "\n",
    "    features_list = []\n",
    "\n",
    "    # Initialiser opensmile (ici avec ComParE_2016 et niveau Functionals)\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals\n",
    "    )\n",
    "    \n",
    "    file_count = 0\n",
    "    \n",
    "    # Parcourir les fichiers audio\n",
    "    for file in os.listdir(audios_dir):\n",
    "        if file.lower().endswith(\".wav\"):\n",
    "            audio_path = os.path.join(audios_dir, file)\n",
    "            \n",
    "            # Extraire dialogue_id et utterance_id à partir du nom de fichier\n",
    "            match = re.match(r\"dia(\\d+)_utt(\\d+)\", file)\n",
    "            if not match:\n",
    "                print(f\"Nom de fichier non conforme : {file}\")\n",
    "                continue\n",
    "            dialogue_id = int(match.group(1))\n",
    "            utterance_id = int(match.group(2))\n",
    "            \n",
    "            try:\n",
    "                # Extraction des caractéristiques avec opensmile\n",
    "                features_df = smile.process_file(audio_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de l'extraction pour {file} : {e}\")\n",
    "                continue\n",
    "\n",
    "            # On récupère la première (et unique) ligne des features extraites\n",
    "            feat_dict = features_df.iloc[0].to_dict()\n",
    "            feat_dict[\"Dialogue_ID\"] = dialogue_id\n",
    "            feat_dict[\"Utterance_ID\"] = utterance_id\n",
    "            \n",
    "            # Récupérer le label d'Emotion correspondant à ce fichier\n",
    "            label_row = labels_df[\n",
    "                (labels_df[\"Dialogue_ID\"] == dialogue_id) & \n",
    "                (labels_df[\"Utterance_ID\"] == utterance_id)\n",
    "            ].iloc[0]  # On prend directement la première ligne correspondante\n",
    "\n",
    "            feat_dict[\"Emotion\"] = label_row[\"Emotion\"]\n",
    "            \n",
    "            features_list.append(feat_dict)\n",
    "            \n",
    "            # Incrémenter le compteur\n",
    "            file_count += 1\n",
    "\n",
    "            # Afficher tous les 100 fichiers traités\n",
    "            if file_count % 100 == 0:\n",
    "                print(f\"Progression : {file_count} fichiers traités\")\n",
    "    \n",
    "    # Créer un DataFrame avec toutes les caractéristiques\n",
    "    if not features_list:\n",
    "        print(f\"Aucun fichier audio traité dans {audios_dir}\")\n",
    "        continue\n",
    "    features_all = pd.DataFrame(features_list)\n",
    "    \n",
    "    # Sélectionner les colonnes de features (exclure les colonnes non-numériques et le label Emotion)\n",
    "    exclude_cols = [\"Dialogue_ID\", \"Utterance_ID\", \"Emotion\"]\n",
    "    feature_cols = [col for col in features_all.columns if col not in exclude_cols]\n",
    "    \n",
    "    X = features_all[feature_cols].values\n",
    "    y = features_all[\"Emotion\"].values  # On utilise uniquement Emotion comme cible\n",
    "\n",
    "    # Appliquer PCA avec n_components=2\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    # 3. Ajouter les composantes PCA réduites au DataFrame\n",
    "    for i in range(X_pca.shape[1]):\n",
    "        features_all[f\"PCA_{i+1}\"] = X_pca[:, i]\n",
    "\n",
    "    # 4. Filtrer les colonnes pour ne garder que les caractéristiques PCA (et Emotion)\n",
    "    columns_to_keep = [\"Emotion\"] + [f\"PCA_{i+1}\" for i in range(X_pca.shape[1])]\n",
    "    features_all = features_all[columns_to_keep]\n",
    "\n",
    "    # 5. Enregistrer le DataFrame avec les caractéristiques dans un CSV\n",
    "    output_csv = os.path.join(dataset_path, folder, f\"features_{folder}_pca.csv\")\n",
    "    features_all.to_csv(output_csv, index=False)\n",
    "    print(f\"Fichier des caractéristiques PCA sauvegardé : {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bbe2167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Traitement du dossier : train\n",
      "Traitement des fichiers : 100/9988 fichiers traités\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m utt_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     feats_df \u001b[38;5;241m=\u001b[39m smile\u001b[38;5;241m.\u001b[39mprocess_file(audio_path)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErreur OpenSMILE sur \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\feature.py:391\u001b[0m, in \u001b[0;36mFeature.process_file\u001b[1;34m(self, file, start, end, root, process_func_args)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_file\u001b[39m(\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    360\u001b[0m     file: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m     process_func_args: typing\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, typing\u001b[38;5;241m.\u001b[39mAny] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    366\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Extract features from an audio file.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    389\u001b[0m \n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 391\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39mprocess_file(\n\u001b[0;32m    392\u001b[0m         file,\n\u001b[0;32m    393\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    394\u001b[0m         end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m    395\u001b[0m         root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    396\u001b[0m         process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    397\u001b[0m     )\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_series_to_frame(series)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:344\u001b[0m, in \u001b[0;36mProcess.process_file\u001b[1;34m(self, file, start, end, root, process_func_args)\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_index_wo_segment(index, root)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m     y, files, starts, ends \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_file(\n\u001b[0;32m    345\u001b[0m         file,\n\u001b[0;32m    346\u001b[0m         root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    347\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    348\u001b[0m         end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m    349\u001b[0m         process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    350\u001b[0m     )\n\u001b[0;32m    352\u001b[0m     index \u001b[38;5;241m=\u001b[39m audformat\u001b[38;5;241m.\u001b[39msegmented_index(files, starts, ends)\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:266\u001b[0m, in \u001b[0;36mProcess._process_file\u001b[1;34m(self, file, idx, root, start, end, process_func_args)\u001b[0m\n\u001b[0;32m    257\u001b[0m     end \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mto_timedelta(end, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate)\n\u001b[0;32m    259\u001b[0m signal, sampling_rate \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mread_audio(\n\u001b[0;32m    260\u001b[0m     file,\n\u001b[0;32m    261\u001b[0m     start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    262\u001b[0m     end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m    263\u001b[0m     root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    264\u001b[0m )\n\u001b[1;32m--> 266\u001b[0m y, files, starts, ends \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_signal(\n\u001b[0;32m    267\u001b[0m     signal,\n\u001b[0;32m    268\u001b[0m     sampling_rate,\n\u001b[0;32m    269\u001b[0m     idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[0;32m    270\u001b[0m     root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    271\u001b[0m     file\u001b[38;5;241m=\u001b[39mfile,\n\u001b[0;32m    272\u001b[0m     process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    273\u001b[0m )\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_offset\u001b[39m(duration, sampling_rate):\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;66;03m# Ensure we get the same precision\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# by storing what is lost due to rounding\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# when reading the file\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     duration_at_sample \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mto_timedelta(\n\u001b[0;32m    280\u001b[0m         audmath\u001b[38;5;241m.\u001b[39msamples(duration\u001b[38;5;241m.\u001b[39mtotal_seconds(), sampling_rate) \u001b[38;5;241m/\u001b[39m sampling_rate\n\u001b[0;32m    281\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:690\u001b[0m, in \u001b[0;36mProcess._process_signal\u001b[1;34m(self, signal, sampling_rate, idx, root, file, start, end, process_func_args)\u001b[0m\n\u001b[0;32m    687\u001b[0m         signal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(signal, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, num_pad)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    689\u001b[0m \u001b[38;5;66;03m# Process signal\u001b[39;00m\n\u001b[1;32m--> 690\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\n\u001b[0;32m    691\u001b[0m     signal,\n\u001b[0;32m    692\u001b[0m     sampling_rate,\n\u001b[0;32m    693\u001b[0m     idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[0;32m    694\u001b[0m     root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    695\u001b[0m     file\u001b[38;5;241m=\u001b[39mfile,\n\u001b[0;32m    696\u001b[0m     process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    697\u001b[0m )\n\u001b[0;32m    699\u001b[0m \u001b[38;5;66;03m# Create index\u001b[39;00m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwin_dur \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:975\u001b[0m, in \u001b[0;36mProcess._call\u001b[1;34m(self, signal, sampling_rate, idx, root, file, process_func_args)\u001b[0m\n\u001b[0;32m    973\u001b[0m     y \u001b[38;5;241m=\u001b[39m [_helper(frames[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, idx]) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_frames)]\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 975\u001b[0m     y \u001b[38;5;241m=\u001b[39m _helper(signal)\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:958\u001b[0m, in \u001b[0;36mProcess._call.<locals>._helper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    949\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_func(\n\u001b[0;32m    950\u001b[0m             np\u001b[38;5;241m.\u001b[39matleast_2d(channel),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m x\n\u001b[0;32m    956\u001b[0m     ]\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_func(\n\u001b[0;32m    959\u001b[0m         x,\n\u001b[0;32m    960\u001b[0m         sampling_rate,\n\u001b[0;32m    961\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mspecial_args,\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprocess_func_args,\n\u001b[0;32m    963\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\opensmile\\core\\smile.py:285\u001b[0m, in \u001b[0;36mSmile._extract\u001b[1;34m(self, signal, sampling_rate)\u001b[0m\n\u001b[0;32m    282\u001b[0m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampleRate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sampling_rate\n\u001b[0;32m    283\u001b[0m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnBits\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m--> 285\u001b[0m smile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smile(options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    286\u001b[0m smile\u001b[38;5;241m.\u001b[39mexternal_sink_set_callback_ex(\n\u001b[0;32m    287\u001b[0m     config\u001b[38;5;241m.\u001b[39mEXTERNAL_OUTPUT_COMPONENT, Smile\u001b[38;5;241m.\u001b[39m_sink_callback(y, starts, ends)\n\u001b[0;32m    288\u001b[0m )\n\u001b[0;32m    289\u001b[0m smile\u001b[38;5;241m.\u001b[39mexternal_audio_source_write_data(\n\u001b[0;32m    290\u001b[0m     config\u001b[38;5;241m.\u001b[39mEXTERNAL_SOURCE_COMPONENT, \u001b[38;5;28mbytes\u001b[39m(x)\n\u001b[0;32m    291\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\opensmile\\core\\smile.py:413\u001b[0m, in \u001b[0;36mSmile._smile\u001b[1;34m(self, options)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Set up smile instance.\"\"\"\u001b[39;00m\n\u001b[0;32m    412\u001b[0m smile \u001b[38;5;241m=\u001b[39m OpenSMILE()\n\u001b[1;32m--> 413\u001b[0m smile\u001b[38;5;241m.\u001b[39minitialize(\n\u001b[0;32m    414\u001b[0m     config_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_path,\n\u001b[0;32m    415\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    416\u001b[0m     loglevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglevel,\n\u001b[0;32m    417\u001b[0m     log_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogfile,\n\u001b[0;32m    418\u001b[0m     debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    419\u001b[0m )\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m smile\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\opensmile\\core\\lib.py:325\u001b[0m, in \u001b[0;36mOpenSMILE.initialize\u001b[1;34m(self, config_file, options, loglevel, debug, console_output, log_file)\u001b[0m\n\u001b[0;32m    322\u001b[0m options_char_arr \u001b[38;5;241m=\u001b[39m c_char_p_arr(options_flat)\n\u001b[0;32m    323\u001b[0m log_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(log_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m log_file \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_smile_result(\n\u001b[1;32m--> 325\u001b[0m     smileapi\u001b[38;5;241m.\u001b[39msmile_initialize(\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smileobj,\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28mbytes\u001b[39m(config_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mlen\u001b[39m(options),\n\u001b[0;32m    329\u001b[0m         options_char_arr,\n\u001b[0;32m    330\u001b[0m         loglevel,\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;28mint\u001b[39m(debug),\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mint\u001b[39m(console_output),\n\u001b[0;32m    333\u001b[0m         log_file,\n\u001b[0;32m    334\u001b[0m     )\n\u001b[0;32m    335\u001b[0m )\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callbacks \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import opensmile\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Chemin du dataset\n",
    "dataset_path = \"dataset_clean\"\n",
    "folders = [\"train\", \"dev\", \"test\"]\n",
    "\n",
    "# Stocker les features bruts + labels pour chaque split\n",
    "all_data = {}\n",
    "\n",
    "# --- 1. Extraction avec OpenSMILE ---\n",
    "for folder in folders:\n",
    "    print(f\"\\n🔍 Traitement du dossier : {folder}\")\n",
    "    csv_path = os.path.join(dataset_path, folder, f\"filtered_{folder}_sent_emo.csv\")\n",
    "    try:\n",
    "        labels_df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lecture CSV : {e}\")\n",
    "        continue\n",
    "\n",
    "    audios_dir = os.path.join(dataset_path, folder, \"audios\")\n",
    "    if not os.path.exists(audios_dir):\n",
    "        print(f\"Dossier audio introuvable : {audios_dir}\")\n",
    "        continue\n",
    "\n",
    "    features_list = []\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals\n",
    "    )\n",
    "\n",
    "    file_count = 0  # Compteur de fichiers traités\n",
    "    total_files = len([f for f in os.listdir(audios_dir) if f.endswith(\".wav\")])  # Nombre total de fichiers\n",
    "\n",
    "    for file in os.listdir(audios_dir):\n",
    "        if file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(audios_dir, file)\n",
    "            match = re.match(r\"dia(\\d+)_utt(\\d+)\", file)\n",
    "            if not match:\n",
    "                continue\n",
    "            dia_id = int(match.group(1))\n",
    "            utt_id = int(match.group(2))\n",
    "\n",
    "            try:\n",
    "                feats_df = smile.process_file(audio_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur OpenSMILE sur {file} : {e}\")\n",
    "                continue\n",
    "\n",
    "            feat_dict = feats_df.iloc[0].to_dict()\n",
    "            feat_dict[\"Dialogue_ID\"] = dia_id\n",
    "            feat_dict[\"Utterance_ID\"] = utt_id\n",
    "\n",
    "            label_row = labels_df[\n",
    "                (labels_df[\"Dialogue_ID\"] == dia_id) & \n",
    "                (labels_df[\"Utterance_ID\"] == utt_id)\n",
    "            ]\n",
    "            if label_row.empty:\n",
    "                continue\n",
    "\n",
    "            label_row = label_row.iloc[0]\n",
    "            feat_dict[\"Emotion\"] = label_row[\"Emotion\"]\n",
    "            feat_dict[\"Sentiment\"] = label_row[\"Sentiment\"]\n",
    "            feat_dict[\"Label\"] = f\"{label_row['Emotion']}_{label_row['Sentiment']}\"\n",
    "\n",
    "            features_list.append(feat_dict)\n",
    "\n",
    "        file_count += 1\n",
    "\n",
    "        # Afficher la progression tous les 100 fichiers\n",
    "        if file_count % 100 == 0 or file_count == total_files:\n",
    "            print(f\"Traitement des fichiers : {file_count}/{total_files} fichiers traités\")\n",
    "\n",
    "    if not features_list:\n",
    "        print(f\"Aucun fichier audio traité dans {folder}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.DataFrame(features_list)\n",
    "    all_data[folder] = df\n",
    "\n",
    "# --- 2. Scaler + PCA ---\n",
    "print(\"\\n⚙️ Prétraitement : StandardScaler + PCA (95%)\")\n",
    "exclude = [\"Dialogue_ID\", \"Utterance_ID\", \"Emotion\", \"Sentiment\", \"Label\"]\n",
    "feature_cols = [col for col in all_data[\"train\"].columns if col not in exclude]\n",
    "\n",
    "# Fit scaler et PCA uniquement sur TRAIN\n",
    "X_train = all_data[\"train\"][feature_cols].values\n",
    "y_train = all_data[\"train\"][\"Label\"].values\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "pca = PCA(n_components=0.95).fit(X_train_scaled)\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "\n",
    "# On ajoute au dataframe\n",
    "for i in range(X_train_pca.shape[1]):\n",
    "    all_data[\"train\"][f\"PCA_{i+1}\"] = X_train_pca[:, i]\n",
    "\n",
    "# --- 3. Appliquer transform sur dev et test ---\n",
    "for split in [\"dev\", \"test\"]:\n",
    "    if split not in all_data:\n",
    "        continue\n",
    "    X_split = all_data[split][feature_cols].values\n",
    "    X_scaled = scaler.transform(X_split)\n",
    "    X_pca = pca.transform(X_scaled)\n",
    "\n",
    "    for i in range(X_pca.shape[1]):\n",
    "        all_data[split][f\"PCA_{i+1}\"] = X_pca[:, i]\n",
    "\n",
    "# --- 4. Sauvegarde des CSV PCA ---\n",
    "for split in all_data:\n",
    "    df = all_data[split]\n",
    "    pca_cols = [col for col in df.columns if col.startswith(\"PCA_\")]\n",
    "    output_df = df[[\"Emotion\"] + pca_cols]\n",
    "    output_path = os.path.join(dataset_path, split, f\"features_{split}_pca2.csv\")\n",
    "    output_df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Sauvegardé : {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be9a10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Charger ton fichier CSV contenant les émotions\n",
    "csv_path = \"dataset_clean/train/filtered_train_sent_emo.csv\"  # Change ce chemin en fonction de ton dataset\n",
    "df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Visualiser la distribution des émotions\n",
    "plt.figure(figsize=(10, 6))\n",
    "df['Emotion'].value_counts().plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution des émotions dans le dataset')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9490c16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Traitement du dossier : train\n",
      "Traitement des fichiers : 100/9988\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m utt_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     feats_df \u001b[38;5;241m=\u001b[39m smile\u001b[38;5;241m.\u001b[39mprocess_file(audio_path)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErreur OpenSMILE sur \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\feature.py:391\u001b[0m, in \u001b[0;36mFeature.process_file\u001b[1;34m(self, file, start, end, root, process_func_args)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_file\u001b[39m(\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    360\u001b[0m     file: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m     process_func_args: typing\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, typing\u001b[38;5;241m.\u001b[39mAny] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    366\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Extract features from an audio file.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    389\u001b[0m \n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 391\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39mprocess_file(\n\u001b[0;32m    392\u001b[0m         file,\n\u001b[0;32m    393\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    394\u001b[0m         end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m    395\u001b[0m         root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    396\u001b[0m         process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    397\u001b[0m     )\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_series_to_frame(series)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:344\u001b[0m, in \u001b[0;36mProcess.process_file\u001b[1;34m(self, file, start, end, root, process_func_args)\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_index_wo_segment(index, root)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m     y, files, starts, ends \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_file(\n\u001b[0;32m    345\u001b[0m         file,\n\u001b[0;32m    346\u001b[0m         root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    347\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    348\u001b[0m         end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m    349\u001b[0m         process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    350\u001b[0m     )\n\u001b[0;32m    352\u001b[0m     index \u001b[38;5;241m=\u001b[39m audformat\u001b[38;5;241m.\u001b[39msegmented_index(files, starts, ends)\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:266\u001b[0m, in \u001b[0;36mProcess._process_file\u001b[1;34m(self, file, idx, root, start, end, process_func_args)\u001b[0m\n\u001b[0;32m    257\u001b[0m     end \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mto_timedelta(end, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate)\n\u001b[0;32m    259\u001b[0m signal, sampling_rate \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mread_audio(\n\u001b[0;32m    260\u001b[0m     file,\n\u001b[0;32m    261\u001b[0m     start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    262\u001b[0m     end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m    263\u001b[0m     root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    264\u001b[0m )\n\u001b[1;32m--> 266\u001b[0m y, files, starts, ends \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_signal(\n\u001b[0;32m    267\u001b[0m     signal,\n\u001b[0;32m    268\u001b[0m     sampling_rate,\n\u001b[0;32m    269\u001b[0m     idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[0;32m    270\u001b[0m     root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    271\u001b[0m     file\u001b[38;5;241m=\u001b[39mfile,\n\u001b[0;32m    272\u001b[0m     process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    273\u001b[0m )\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_offset\u001b[39m(duration, sampling_rate):\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;66;03m# Ensure we get the same precision\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# by storing what is lost due to rounding\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# when reading the file\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     duration_at_sample \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mto_timedelta(\n\u001b[0;32m    280\u001b[0m         audmath\u001b[38;5;241m.\u001b[39msamples(duration\u001b[38;5;241m.\u001b[39mtotal_seconds(), sampling_rate) \u001b[38;5;241m/\u001b[39m sampling_rate\n\u001b[0;32m    281\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:690\u001b[0m, in \u001b[0;36mProcess._process_signal\u001b[1;34m(self, signal, sampling_rate, idx, root, file, start, end, process_func_args)\u001b[0m\n\u001b[0;32m    687\u001b[0m         signal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(signal, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, num_pad)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    689\u001b[0m \u001b[38;5;66;03m# Process signal\u001b[39;00m\n\u001b[1;32m--> 690\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\n\u001b[0;32m    691\u001b[0m     signal,\n\u001b[0;32m    692\u001b[0m     sampling_rate,\n\u001b[0;32m    693\u001b[0m     idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[0;32m    694\u001b[0m     root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m    695\u001b[0m     file\u001b[38;5;241m=\u001b[39mfile,\n\u001b[0;32m    696\u001b[0m     process_func_args\u001b[38;5;241m=\u001b[39mprocess_func_args,\n\u001b[0;32m    697\u001b[0m )\n\u001b[0;32m    699\u001b[0m \u001b[38;5;66;03m# Create index\u001b[39;00m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwin_dur \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:975\u001b[0m, in \u001b[0;36mProcess._call\u001b[1;34m(self, signal, sampling_rate, idx, root, file, process_func_args)\u001b[0m\n\u001b[0;32m    973\u001b[0m     y \u001b[38;5;241m=\u001b[39m [_helper(frames[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, idx]) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_frames)]\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 975\u001b[0m     y \u001b[38;5;241m=\u001b[39m _helper(signal)\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audinterface\\core\\process.py:958\u001b[0m, in \u001b[0;36mProcess._call.<locals>._helper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    949\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_func(\n\u001b[0;32m    950\u001b[0m             np\u001b[38;5;241m.\u001b[39matleast_2d(channel),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m x\n\u001b[0;32m    956\u001b[0m     ]\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_func(\n\u001b[0;32m    959\u001b[0m         x,\n\u001b[0;32m    960\u001b[0m         sampling_rate,\n\u001b[0;32m    961\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mspecial_args,\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprocess_func_args,\n\u001b[0;32m    963\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\opensmile\\core\\smile.py:285\u001b[0m, in \u001b[0;36mSmile._extract\u001b[1;34m(self, signal, sampling_rate)\u001b[0m\n\u001b[0;32m    282\u001b[0m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampleRate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sampling_rate\n\u001b[0;32m    283\u001b[0m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnBits\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m--> 285\u001b[0m smile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smile(options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    286\u001b[0m smile\u001b[38;5;241m.\u001b[39mexternal_sink_set_callback_ex(\n\u001b[0;32m    287\u001b[0m     config\u001b[38;5;241m.\u001b[39mEXTERNAL_OUTPUT_COMPONENT, Smile\u001b[38;5;241m.\u001b[39m_sink_callback(y, starts, ends)\n\u001b[0;32m    288\u001b[0m )\n\u001b[0;32m    289\u001b[0m smile\u001b[38;5;241m.\u001b[39mexternal_audio_source_write_data(\n\u001b[0;32m    290\u001b[0m     config\u001b[38;5;241m.\u001b[39mEXTERNAL_SOURCE_COMPONENT, \u001b[38;5;28mbytes\u001b[39m(x)\n\u001b[0;32m    291\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\opensmile\\core\\smile.py:413\u001b[0m, in \u001b[0;36mSmile._smile\u001b[1;34m(self, options)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Set up smile instance.\"\"\"\u001b[39;00m\n\u001b[0;32m    412\u001b[0m smile \u001b[38;5;241m=\u001b[39m OpenSMILE()\n\u001b[1;32m--> 413\u001b[0m smile\u001b[38;5;241m.\u001b[39minitialize(\n\u001b[0;32m    414\u001b[0m     config_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_path,\n\u001b[0;32m    415\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    416\u001b[0m     loglevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglevel,\n\u001b[0;32m    417\u001b[0m     log_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogfile,\n\u001b[0;32m    418\u001b[0m     debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    419\u001b[0m )\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m smile\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\opensmile\\core\\lib.py:325\u001b[0m, in \u001b[0;36mOpenSMILE.initialize\u001b[1;34m(self, config_file, options, loglevel, debug, console_output, log_file)\u001b[0m\n\u001b[0;32m    322\u001b[0m options_char_arr \u001b[38;5;241m=\u001b[39m c_char_p_arr(options_flat)\n\u001b[0;32m    323\u001b[0m log_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(log_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m log_file \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_smile_result(\n\u001b[1;32m--> 325\u001b[0m     smileapi\u001b[38;5;241m.\u001b[39msmile_initialize(\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smileobj,\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28mbytes\u001b[39m(config_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mlen\u001b[39m(options),\n\u001b[0;32m    329\u001b[0m         options_char_arr,\n\u001b[0;32m    330\u001b[0m         loglevel,\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;28mint\u001b[39m(debug),\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mint\u001b[39m(console_output),\n\u001b[0;32m    333\u001b[0m         log_file,\n\u001b[0;32m    334\u001b[0m     )\n\u001b[0;32m    335\u001b[0m )\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callbacks \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import opensmile\n",
    "import pandas as pd\n",
    "\n",
    "# Chemin du dataset\n",
    "dataset_path = \"dataset_clean\"\n",
    "folders = [\"train\", \"dev\", \"test\"]\n",
    "\n",
    "# Dictionnaire pour stocker les données traitées\n",
    "all_data = {}\n",
    "\n",
    "for folder in folders:\n",
    "    print(f\"\\n🔍 Traitement du dossier : {folder}\")\n",
    "    csv_path = os.path.join(dataset_path, folder, f\"filtered_{folder}_sent_emo.csv\")\n",
    "    \n",
    "    try:\n",
    "        labels_df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lecture CSV : {e}\")\n",
    "        continue\n",
    "\n",
    "    audios_dir = os.path.join(dataset_path, folder, \"audios\")\n",
    "    if not os.path.exists(audios_dir):\n",
    "        print(f\"Dossier audio introuvable : {audios_dir}\")\n",
    "        continue\n",
    "\n",
    "    features_list = []\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals\n",
    "    )\n",
    "\n",
    "    total_files = len([f for f in os.listdir(audios_dir) if f.endswith(\".wav\")])\n",
    "    file_count = 0  # Compteur des fichiers traités\n",
    "\n",
    "    for file in os.listdir(audios_dir):\n",
    "        if file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(audios_dir, file)\n",
    "            match = re.match(r\"dia(\\d+)_utt(\\d+)\", file)\n",
    "            if not match:\n",
    "                continue\n",
    "            dia_id = int(match.group(1))\n",
    "            utt_id = int(match.group(2))\n",
    "\n",
    "            try:\n",
    "                feats_df = smile.process_file(audio_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur OpenSMILE sur {file} : {e}\")\n",
    "                continue\n",
    "\n",
    "            feat_dict = feats_df.iloc[0].to_dict()\n",
    "            feat_dict[\"Dialogue_ID\"] = dia_id\n",
    "            feat_dict[\"Utterance_ID\"] = utt_id\n",
    "\n",
    "            label_row = labels_df[\n",
    "                (labels_df[\"Dialogue_ID\"] == dia_id) & \n",
    "                (labels_df[\"Utterance_ID\"] == utt_id)\n",
    "            ]\n",
    "            if label_row.empty:\n",
    "                continue\n",
    "\n",
    "            label_row = label_row.iloc[0]\n",
    "            feat_dict[\"Emotion\"] = label_row[\"Emotion\"]\n",
    "            feat_dict[\"Sentiment\"] = label_row[\"Sentiment\"]\n",
    "            feat_dict[\"Label\"] = f\"{label_row['Emotion']}_{label_row['Sentiment']}\"\n",
    "\n",
    "            features_list.append(feat_dict)\n",
    "\n",
    "        # Affichage de la progression tous les 100 fichiers\n",
    "        file_count += 1\n",
    "        if file_count % 100 == 0:\n",
    "            print(f\"Traitement des fichiers : {file_count}/{total_files}\")\n",
    "\n",
    "    if features_list:\n",
    "        df = pd.DataFrame(features_list)\n",
    "        all_data[folder] = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09239e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Traitement du dossier : train\n",
      "Traitement des fichiers : 10/9988\n",
      "Traitement des fichiers : 20/9988\n",
      "Traitement des fichiers : 30/9988\n",
      "Traitement des fichiers : 40/9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function OpenSMILE.external_sink_set_callback_ex.<locals>.internal_callback_ex at 0x0000023763AABF60>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\opensmile\\core\\lib.py\", line 458, in internal_callback_ex\n",
      "    def internal_callback_ex(data, nt, n, meta: POINTER(FrameMetaData), _):\n",
      "\n",
      "KeyboardInterrupt: \n",
      "C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\opensmile\\core\\smile.py:297: UserWarning: Segment too short, filling with NaN.\n",
      "  warnings.warn(UserWarning(\"Segment too short, filling with NaN.\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement des fichiers : 50/9988\n",
      "Traitement des fichiers : 60/9988\n",
      "Traitement des fichiers : 70/9988\n",
      "Traitement des fichiers : 80/9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function OpenSMILE.external_sink_set_callback_ex.<locals>.internal_callback_ex at 0x0000023763AA8540>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\opensmile\\core\\lib.py\", line 458, in internal_callback_ex\n",
      "    def internal_callback_ex(data, nt, n, meta: POINTER(FrameMetaData), _):\n",
      "\n",
      "KeyboardInterrupt: \n",
      "C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\opensmile\\core\\smile.py:297: UserWarning: Segment too short, filling with NaN.\n",
      "  warnings.warn(UserWarning(\"Segment too short, filling with NaN.\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement des fichiers : 90/9988\n",
      "Traitement des fichiers : 100/9988\n",
      "Traitement des fichiers : 110/9988\n",
      "Traitement des fichiers : 120/9988\n",
      "Traitement des fichiers : 130/9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function OpenSMILE.external_sink_set_callback_ex.<locals>.internal_callback_ex at 0x0000023763AA8540>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\opensmile\\core\\lib.py\", line 458, in internal_callback_ex\n",
      "    def internal_callback_ex(data, nt, n, meta: POINTER(FrameMetaData), _):\n",
      "\n",
      "KeyboardInterrupt: \n",
      "C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\opensmile\\core\\smile.py:297: UserWarning: Segment too short, filling with NaN.\n",
      "  warnings.warn(UserWarning(\"Segment too short, filling with NaN.\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement des fichiers : 140/9988\n",
      "Traitement des fichiers : 150/9988\n",
      "Traitement des fichiers : 160/9988\n",
      "Traitement des fichiers : 170/9988\n",
      "Traitement des fichiers : 180/9988\n",
      "Traitement des fichiers : 190/9988\n",
      "Traitement des fichiers : 200/9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function OpenSMILE.external_sink_set_callback_ex.<locals>.internal_callback_ex at 0x0000023763AC0040>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\opensmile\\core\\lib.py\", line 458, in internal_callback_ex\n",
      "    def internal_callback_ex(data, nt, n, meta: POINTER(FrameMetaData), _):\n",
      "\n",
      "KeyboardInterrupt: \n",
      "C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\opensmile\\core\\smile.py:297: UserWarning: Segment too short, filling with NaN.\n",
      "  warnings.warn(UserWarning(\"Segment too short, filling with NaN.\"))\n",
      "Exception ignored on calling ctypes callback function: <function OpenSMILE.external_sink_set_callback_ex.<locals>.internal_callback_ex at 0x0000023763AC3E20>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\opensmile\\core\\lib.py\", line 458, in internal_callback_ex\n",
      "    def internal_callback_ex(data, nt, n, meta: POINTER(FrameMetaData), _):\n",
      "\n",
      "KeyboardInterrupt: \n",
      "C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\opensmile\\core\\smile.py:297: UserWarning: Segment too short, filling with NaN.\n",
      "  warnings.warn(UserWarning(\"Segment too short, filling with NaN.\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement des fichiers : 210/9988\n",
      "Traitement des fichiers : 220/9988\n",
      "Traitement des fichiers : 230/9988\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import opensmile\n",
    "import pandas as pd\n",
    "\n",
    "# Chemin du dataset\n",
    "dataset_path = \"dataset_clean\"\n",
    "folders = [\"train\", \"dev\", \"test\"]\n",
    "\n",
    "# Dictionnaire pour stocker les données traitées\n",
    "all_data = {}\n",
    "\n",
    "for folder in folders:\n",
    "    print(f\"\\n🔍 Traitement du dossier : {folder}\")\n",
    "    csv_path = os.path.join(dataset_path, folder, f\"filtered_{folder}_sent_emo.csv\")\n",
    "    \n",
    "    try:\n",
    "        labels_df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lecture CSV : {e}\")\n",
    "        continue\n",
    "\n",
    "    audios_dir = os.path.join(dataset_path, folder, \"audios\")\n",
    "    if not os.path.exists(audios_dir):\n",
    "        print(f\"Dossier audio introuvable : {audios_dir}\")\n",
    "        continue\n",
    "\n",
    "    features_list = []\n",
    "    \n",
    "    # Utiliser GeMAPSv01b à la place de GeMAPSv01a\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.GeMAPSv01b,  # Changer ici pour GeMAPSv01b\n",
    "        feature_level=opensmile.FeatureLevel.Functionals\n",
    "    )\n",
    "\n",
    "    total_files = len([f for f in os.listdir(audios_dir) if f.endswith(\".wav\")])\n",
    "    file_count = 0  # Compteur des fichiers traités\n",
    "\n",
    "    for file in os.listdir(audios_dir):\n",
    "        if file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(audios_dir, file)\n",
    "            match = re.match(r\"dia(\\d+)_utt(\\d+)\", file)\n",
    "            if not match:\n",
    "                continue\n",
    "            dia_id = int(match.group(1))\n",
    "            utt_id = int(match.group(2))\n",
    "            try:\n",
    "                feats_df = smile.process_file(audio_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur OpenSMILE sur {file} : {e}\")\n",
    "                continue\n",
    "            feat_dict = feats_df.iloc[0].to_dict()\n",
    "            feat_dict[\"Dialogue_ID\"] = dia_id\n",
    "            feat_dict[\"Utterance_ID\"] = utt_id\n",
    "\n",
    "            label_row = labels_df[\n",
    "                (labels_df[\"Dialogue_ID\"] == dia_id) & \n",
    "                (labels_df[\"Utterance_ID\"] == utt_id)\n",
    "            ]\n",
    "            if label_row.empty:\n",
    "                continue\n",
    "\n",
    "            label_row = label_row.iloc[0]\n",
    "            feat_dict[\"Emotion\"] = label_row[\"Emotion\"]\n",
    "            feat_dict[\"Sentiment\"] = label_row[\"Sentiment\"]\n",
    "            feat_dict[\"Label\"] = f\"{label_row['Emotion']}_{label_row['Sentiment']}\"\n",
    "\n",
    "            features_list.append(feat_dict)\n",
    "\n",
    "        # Affichage de la progression tous les 100 fichiers\n",
    "        file_count += 1\n",
    "        if file_count % 100 == 0:\n",
    "            print(f\"Traitement des fichiers : {file_count}\")\n",
    "\n",
    "    if features_list:\n",
    "        df = pd.DataFrame(features_list)\n",
    "        all_data[folder] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04473b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Obtaining dependency information for librosa from https://files.pythonhosted.org/packages/b5/ba/c63c5786dfee4c3417094c4b00966e61e4a63efecee22cb7b4c0387dda83/librosa-0.11.0-py3-none-any.whl.metadata\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Obtaining dependency information for audioread>=2.1.9 from https://files.pythonhosted.org/packages/57/8d/30aa32745af16af0a9a650115fbe81bde7c610ed5c21b381fca0196f3a7f/audioread-3.0.1-py3-none-any.whl.metadata\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from librosa) (0.57.1)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from librosa) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from librosa) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from librosa) (0.13.0)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Obtaining dependency information for pooch>=1.1 from https://files.pythonhosted.org/packages/a8/87/77cc11c7a9ea9fd05503def69e3d18605852cd0d4b0d3b8f15bbeb3ef1d1/pooch-1.8.2-py3-none-any.whl.metadata\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Obtaining dependency information for soxr>=0.3.2 from https://files.pythonhosted.org/packages/86/94/6a7e91bea7e6ca193ee429869b8f18548cd79759e064021ecb5756024c7c/soxr-0.5.0.post1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached soxr-0.5.0.post1-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from librosa) (0.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.40.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (23.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2023.7.22)\n",
      "Using cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached soxr-0.5.0.post1-cp311-cp311-win_amd64.whl (166 kB)\n",
      "Installing collected packages: soxr, audioread, pooch, librosa\n",
      "Successfully installed audioread-3.0.1 librosa-0.11.0 pooch-1.8.2 soxr-0.5.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7be488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Traitement du dossier : train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boucceredj\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 44\u001b[0m\n\u001b[0;32m     40\u001b[0m utt_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Charger l'audio\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     y, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(audio_path, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# Extraire des caractéristiques (par exemple, MFCC)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     mfccs \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr, n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\audio.py:170\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     57\u001b[0m     path: Union[\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[Any], sf\u001b[38;5;241m.\u001b[39mSoundFile, audioread\u001b[38;5;241m.\u001b[39mAudioFile, BinaryIO\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     res_type: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoxr_hq\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     67\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m     68\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load an audio file as a floating point time series.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Audio will be automatically resampled to the given rate\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03m    >>> y, sr = librosa.load(aro)\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mtuple\u001b[39m(audioread\u001b[38;5;241m.\u001b[39mavailable_backends())):\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;66;03m# Force the audioread loader if we have a reader object already\u001b[39;00m\n\u001b[0;32m    172\u001b[0m         y, sr_native \u001b[38;5;241m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;66;03m# Otherwise try soundfile first, and then fall back if necessary\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\audioread\\__init__.py:99\u001b[0m, in \u001b[0;36mavailable_backends\u001b[1;34m(flush_cache)\u001b[0m\n\u001b[0;32m     96\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(maddec\u001b[38;5;241m.\u001b[39mMadAudioFile)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# FFmpeg.\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ffdec\u001b[38;5;241m.\u001b[39mavailable():\n\u001b[0;32m    100\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(ffdec\u001b[38;5;241m.\u001b[39mFFmpegAudioFile)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Cache the backends we found\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\audioread\\ffdec.py:113\u001b[0m, in \u001b[0;36mavailable\u001b[1;34m()\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     proc\u001b[38;5;241m.\u001b[39mcommunicate()\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_communicate(\u001b[38;5;28minput\u001b[39m, endtime, timeout)\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\subprocess.py:1626\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remaining_time(endtime))\n\u001b[0;32m   1627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m   1628\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock()\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[0;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "# Chemin du dataset\n",
    "dataset_path = \"dataset_clean\"\n",
    "folders = [\"train\", \"dev\", \"test\"]\n",
    "\n",
    "# Dictionnaire pour stocker les données traitées\n",
    "all_data = {}\n",
    "\n",
    "for folder in folders:\n",
    "    print(f\"\\n🔍 Traitement du dossier : {folder}\")\n",
    "    csv_path = os.path.join(dataset_path, folder, f\"filtered_{folder}_sent_emo.csv\")\n",
    "    \n",
    "    try:\n",
    "        labels_df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lecture CSV : {e}\")\n",
    "        continue\n",
    "\n",
    "    audios_dir = os.path.join(dataset_path, folder, \"audios\")\n",
    "    if not os.path.exists(audios_dir):\n",
    "        print(f\"Dossier audio introuvable : {audios_dir}\")\n",
    "        continue\n",
    "\n",
    "    features_list = []\n",
    "\n",
    "    total_files = len([f for f in os.listdir(audios_dir) if f.endswith(\".wav\")])\n",
    "    file_count = 0  # Compteur des fichiers traités\n",
    "\n",
    "    for file in os.listdir(audios_dir):\n",
    "        if file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(audios_dir, file)\n",
    "            match = re.match(r\"dia(\\d+)_utt(\\d+)\", file)\n",
    "            if not match:\n",
    "                continue\n",
    "            dia_id = int(match.group(1))\n",
    "            utt_id = int(match.group(2))\n",
    "\n",
    "            try:\n",
    "                # Charger l'audio\n",
    "                y, sr = librosa.load(audio_path, sr=None)\n",
    "                # Extraire des caractéristiques (par exemple, MFCC)\n",
    "                mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "                features = mfccs.mean(axis=1)  # Moyenne des MFCCs\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur Librosa sur {file} : {e}\")\n",
    "                continue\n",
    "\n",
    "            feat_dict = {f\"MFCC_{i+1}\": features[i] for i in range(len(features))}\n",
    "            feat_dict[\"Dialogue_ID\"] = dia_id\n",
    "            feat_dict[\"Utterance_ID\"] = utt_id\n",
    "\n",
    "            label_row = labels_df[\n",
    "                (labels_df[\"Dialogue_ID\"] == dia_id) & \n",
    "                (labels_df[\"Utterance_ID\"] == utt_id)\n",
    "            ]\n",
    "            if label_row.empty:\n",
    "                continue\n",
    "\n",
    "            label_row = label_row.iloc[0]\n",
    "            feat_dict[\"Emotion\"] = label_row[\"Emotion\"]\n",
    "            feat_dict[\"Sentiment\"] = label_row[\"Sentiment\"]\n",
    "            feat_dict[\"Label\"] = f\"{label_row['Emotion']}_{label_row['Sentiment']}\"\n",
    "\n",
    "            features_list.append(feat_dict)\n",
    "\n",
    "        # Affichage de la progression tous les 100 fichiers\n",
    "        file_count += 1\n",
    "        if file_count % 100 == 0:\n",
    "            print(f\"Traitement des fichiers : {file_count}\")\n",
    "\n",
    "    if features_list:\n",
    "        df = pd.DataFrame(features_list)\n",
    "        all_data[folder] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69f28339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Collecting imbalanced-learn\n",
      "  Obtaining dependency information for imbalanced-learn from https://files.pythonhosted.org/packages/9d/41/721fec82606242a2072ee909086ff918dfad7d0199a9dfd4928df9c72494/imbalanced_learn-0.13.0-py3-none-any.whl.metadata\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
      "  Obtaining dependency information for sklearn-compat<1,>=0.1 from https://files.pythonhosted.org/packages/f0/a8/ad69cf130fbd017660cdd64abbef3f28135d9e2e15fe3002e03c5be0ca38/sklearn_compat-0.1.3-py3-none-any.whl.metadata\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\boucceredj\\anaconda3\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "   ---------------------------------------- 0.0/238.4 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 122.9/238.4 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 204.8/238.4 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  235.5/238.4 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  235.5/238.4 kB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- 238.4/238.4 kB 970.8 kB/s eta 0:00:00\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn\n",
      "  Attempting uninstall: imbalanced-learn\n",
      "    Found existing installation: imbalanced-learn 0.10.1\n",
      "    Uninstalling imbalanced-learn-0.10.1:\n",
      "      Successfully uninstalled imbalanced-learn-0.10.1\n",
      "Successfully installed imbalanced-learn-0.13.0 sklearn-compat-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d2e297",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 👇 Si tu viens de ton script d’extraction\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# all_data = {\"train\": df_train, \"dev\": df_dev, \"test\": df_test}\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 1. Fusion des données\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_data\u001b[38;5;241m.\u001b[39mvalues(), ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 2. Sélection des features MFCC\u001b[39;00m\n\u001b[0;32m     24\u001b[0m feature_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMFCC_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m13\u001b[39m)]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import collections\n",
    "\n",
    "# 👇 Si tu viens de ton script d’extraction\n",
    "# all_data = {\"train\": df_train, \"dev\": df_dev, \"test\": df_test}\n",
    "\n",
    "# 1. Fusion des données\n",
    "combined_df = pd.concat(all_data.values(), ignore_index=True)\n",
    "\n",
    "# 2. Sélection des features MFCC\n",
    "feature_cols = [f\"MFCC_{i+1}\" for i in range(13)]\n",
    "X = combined_df[feature_cols].values\n",
    "y = combined_df[\"Label\"].values  # ou \"Label\" si tu veux utiliser emotion + sentiment\n",
    "\n",
    "# 3. Standardisation\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 4. Split train/test (tu peux aussi faire train=all_data[\"train\"], test=all_data[\"test\"] si tu veux garder la logique de split par fichier)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 5. Oversampling (Random Over Sampling pour équilibrer les classes)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Affichage de la répartition des classes avant et après oversampling\n",
    "print(\"Avant oversampling:\", collections.Counter(y_train))\n",
    "print(\"Après oversampling:\", collections.Counter(y_train_resampled))\n",
    "\n",
    "# 6. Liste des modèles à tester\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"SVM\": SVC(kernel='rbf', probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Naïve Bayes\": GaussianNB(),\n",
    "    \"MLP (Neural Network)\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "# 7. Tester les modèles\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔍 Test du modèle : {name}\")\n",
    "    \n",
    "    # Entraînement sur les données oversamplées\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"🎯 Précision : {acc:.4f}\")\n",
    "\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_model = (name, model)\n",
    "\n",
    "    print(\"📊 Rapport de classification :\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 8. Résumé\n",
    "print(\"\\n✅ Meilleur modèle :\", best_model[0])\n",
    "print(f\"🎯 Meilleure précision : {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00106882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3850bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Traitement du dossier : train\n",
      "Traitement des fichiers : 100\n",
      "Traitement des fichiers : 200\n",
      "Traitement des fichiers : 300\n",
      "Traitement des fichiers : 400\n",
      "Traitement des fichiers : 500\n",
      "Traitement des fichiers : 600\n",
      "Traitement des fichiers : 700\n",
      "Traitement des fichiers : 800\n",
      "Traitement des fichiers : 900\n",
      "Traitement des fichiers : 1000\n",
      "Traitement des fichiers : 1100\n",
      "Traitement des fichiers : 1200\n",
      "Traitement des fichiers : 1300\n",
      "Traitement des fichiers : 1400\n",
      "Traitement des fichiers : 1500\n",
      "Traitement des fichiers : 1600\n",
      "Traitement des fichiers : 1700\n",
      "Traitement des fichiers : 1800\n",
      "Traitement des fichiers : 1900\n",
      "Traitement des fichiers : 2000\n",
      "Traitement des fichiers : 2100\n",
      "Traitement des fichiers : 2200\n",
      "Traitement des fichiers : 2300\n",
      "Traitement des fichiers : 2400\n",
      "Traitement des fichiers : 2500\n",
      "Traitement des fichiers : 2600\n",
      "Traitement des fichiers : 2700\n",
      "Traitement des fichiers : 2800\n",
      "Traitement des fichiers : 2900\n",
      "Traitement des fichiers : 3000\n",
      "Traitement des fichiers : 3100\n",
      "Traitement des fichiers : 3200\n",
      "Traitement des fichiers : 3300\n",
      "Traitement des fichiers : 3400\n",
      "Traitement des fichiers : 3500\n",
      "Traitement des fichiers : 3600\n",
      "Traitement des fichiers : 3700\n",
      "Traitement des fichiers : 3800\n",
      "Traitement des fichiers : 3900\n",
      "Traitement des fichiers : 4000\n",
      "Traitement des fichiers : 4100\n",
      "Traitement des fichiers : 4200\n",
      "Traitement des fichiers : 4300\n",
      "Traitement des fichiers : 4400\n",
      "Traitement des fichiers : 4500\n",
      "Traitement des fichiers : 4600\n",
      "Traitement des fichiers : 4700\n",
      "Traitement des fichiers : 4800\n",
      "Traitement des fichiers : 4900\n",
      "Traitement des fichiers : 5000\n",
      "Traitement des fichiers : 5100\n",
      "Traitement des fichiers : 5200\n",
      "Traitement des fichiers : 5300\n",
      "Traitement des fichiers : 5400\n",
      "Traitement des fichiers : 5500\n",
      "Traitement des fichiers : 5600\n",
      "Traitement des fichiers : 5700\n",
      "Traitement des fichiers : 5800\n",
      "Traitement des fichiers : 5900\n",
      "Traitement des fichiers : 6000\n",
      "Traitement des fichiers : 6100\n",
      "Traitement des fichiers : 6200\n",
      "Traitement des fichiers : 6300\n",
      "Traitement des fichiers : 6400\n",
      "Traitement des fichiers : 6500\n",
      "Traitement des fichiers : 6600\n",
      "Traitement des fichiers : 6700\n",
      "Traitement des fichiers : 6800\n",
      "Traitement des fichiers : 6900\n",
      "Traitement des fichiers : 7000\n",
      "Traitement des fichiers : 7100\n",
      "Traitement des fichiers : 7200\n",
      "Traitement des fichiers : 7300\n",
      "Traitement des fichiers : 7400\n",
      "Traitement des fichiers : 7500\n",
      "Traitement des fichiers : 7600\n",
      "Traitement des fichiers : 7700\n",
      "Traitement des fichiers : 7800\n",
      "Traitement des fichiers : 7900\n",
      "Traitement des fichiers : 8000\n",
      "Traitement des fichiers : 8100\n",
      "Traitement des fichiers : 8200\n",
      "Traitement des fichiers : 8300\n",
      "Traitement des fichiers : 8400\n",
      "Traitement des fichiers : 8500\n",
      "Traitement des fichiers : 8600\n",
      "Traitement des fichiers : 8700\n",
      "Traitement des fichiers : 8800\n",
      "Traitement des fichiers : 8900\n",
      "Traitement des fichiers : 9000\n",
      "Traitement des fichiers : 9100\n",
      "Traitement des fichiers : 9200\n",
      "Traitement des fichiers : 9300\n",
      "Traitement des fichiers : 9400\n",
      "Traitement des fichiers : 9500\n",
      "Traitement des fichiers : 9600\n",
      "Traitement des fichiers : 9700\n",
      "Traitement des fichiers : 9800\n",
      "Traitement des fichiers : 9900\n",
      "Fichier des caractéristiques sauvegardé : dataset_clean\\train\\features_train_librosa.csv\n",
      "\n",
      "🔍 Traitement du dossier : dev\n",
      "Traitement des fichiers : 100\n",
      "Traitement des fichiers : 200\n",
      "Traitement des fichiers : 300\n",
      "Traitement des fichiers : 400\n",
      "Traitement des fichiers : 500\n",
      "Traitement des fichiers : 600\n",
      "Traitement des fichiers : 700\n",
      "Traitement des fichiers : 800\n",
      "Traitement des fichiers : 900\n",
      "Traitement des fichiers : 1000\n",
      "Traitement des fichiers : 1100\n",
      "Fichier des caractéristiques sauvegardé : dataset_clean\\dev\\features_dev_librosa.csv\n",
      "\n",
      "🔍 Traitement du dossier : test\n",
      "Traitement des fichiers : 100\n",
      "Traitement des fichiers : 200\n",
      "Traitement des fichiers : 300\n",
      "Traitement des fichiers : 400\n",
      "Traitement des fichiers : 500\n",
      "Traitement des fichiers : 600\n",
      "Traitement des fichiers : 700\n",
      "Traitement des fichiers : 800\n",
      "Traitement des fichiers : 900\n",
      "Traitement des fichiers : 1000\n",
      "Traitement des fichiers : 1100\n",
      "Traitement des fichiers : 1200\n",
      "Traitement des fichiers : 1300\n",
      "Traitement des fichiers : 1400\n",
      "Traitement des fichiers : 1500\n",
      "Traitement des fichiers : 1600\n",
      "Traitement des fichiers : 1700\n",
      "Traitement des fichiers : 1800\n",
      "Traitement des fichiers : 1900\n",
      "Traitement des fichiers : 2000\n",
      "Traitement des fichiers : 2100\n",
      "Traitement des fichiers : 2200\n",
      "Traitement des fichiers : 2300\n",
      "Traitement des fichiers : 2400\n",
      "Traitement des fichiers : 2500\n",
      "Traitement des fichiers : 2600\n",
      "Fichier des caractéristiques sauvegardé : dataset_clean\\test\\features_test_librosa.csv\n"
     ]
    }
   ],
   "source": [
    "# Code updated to remove the tonnetz feature\n",
    "\n",
    "import os\n",
    "import re\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "# Chemin du dataset\n",
    "dataset_path = \"dataset_clean\"\n",
    "folders = [\"train\", \"dev\", \"test\"]\n",
    "\n",
    "# Dictionnaire pour stocker les données traitées\n",
    "all_data = {}\n",
    "\n",
    "for folder in folders:\n",
    "    print(f\"\\n🔍 Traitement du dossier : {folder}\")\n",
    "    csv_path = os.path.join(dataset_path, folder, f\"filtered_{folder}_sent_emo.csv\")\n",
    "    \n",
    "    try:\n",
    "        labels_df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lecture CSV : {e}\")\n",
    "        continue\n",
    "\n",
    "    audios_dir = os.path.join(dataset_path, folder, \"audios\")\n",
    "    if not os.path.exists(audios_dir):\n",
    "        print(f\"Dossier audio introuvable : {audios_dir}\")\n",
    "        continue\n",
    "\n",
    "    features_list = []\n",
    "\n",
    "    total_files = len([f for f in os.listdir(audios_dir) if f.endswith(\".wav\")])\n",
    "    file_count = 0  # Compteur des fichiers traités\n",
    "\n",
    "    for file in os.listdir(audios_dir):\n",
    "        if file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(audios_dir, file)\n",
    "            match = re.match(r\"dia(\\d+)_utt(\\d+)\", file)\n",
    "            if not match:\n",
    "                continue\n",
    "            dia_id = int(match.group(1))\n",
    "            utt_id = int(match.group(2))\n",
    "\n",
    "            try:\n",
    "                # Charger l'audio\n",
    "                y, sr = librosa.load(audio_path, sr=None)\n",
    "                \n",
    "                # Extraire les caractéristiques audio\n",
    "                mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "                chroma = librosa.feature.chroma_stft(y=y, sr=sr, n_fft=256)\n",
    "                spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr, n_fft=256)\n",
    "                zcr = librosa.feature.zero_crossing_rate(y=y)\n",
    "                rmse = librosa.feature.rms(y=y)\n",
    "\n",
    "                # Calculer les moyennes pour chaque caractéristique\n",
    "                features = {\n",
    "                    **{f\"MFCC_{i+1}\": mfccs[i].mean() for i in range(13)},\n",
    "                    **{f\"Chroma_{i+1}\": chroma[i].mean() for i in range(12)},\n",
    "                    \"Spectral_Rolloff\": spectral_rolloff.mean(),\n",
    "                    \"Zero_Crossing_Rate\": zcr.mean(),\n",
    "                    \"RMSE\": rmse.mean(),\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erreur Librosa sur {file} : {e}\")\n",
    "                continue\n",
    "\n",
    "            feat_dict = {**features, \"Dialogue_ID\": dia_id, \"Utterance_ID\": utt_id}\n",
    "\n",
    "            label_row = labels_df[\n",
    "                (labels_df[\"Dialogue_ID\"] == dia_id) & \n",
    "                (labels_df[\"Utterance_ID\"] == utt_id)\n",
    "            ]\n",
    "            if label_row.empty:\n",
    "                continue\n",
    "\n",
    "            label_row = label_row.iloc[0]\n",
    "            feat_dict[\"Emotion\"] = label_row[\"Emotion\"]\n",
    "            feat_dict[\"Sentiment\"] = label_row[\"Sentiment\"]\n",
    "            feat_dict[\"Label\"] = f\"{label_row['Emotion']}_{label_row['Sentiment']}\" \n",
    "\n",
    "            features_list.append(feat_dict)\n",
    "\n",
    "        # Affichage de la progression tous les 100 fichiers\n",
    "        file_count += 1\n",
    "        if file_count % 100 == 0:\n",
    "            print(f\"Traitement des fichiers : {file_count}\")\n",
    "\n",
    "    if features_list:\n",
    "        df = pd.DataFrame(features_list)\n",
    "        all_data[folder] = df\n",
    "        \n",
    "        # Sauvegarder dans un fichier CSV\n",
    "        output_csv = os.path.join(dataset_path, folder, f\"features_{folder}_librosa.csv\")\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"Fichier des caractéristiques sauvegardé : {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41a00b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
