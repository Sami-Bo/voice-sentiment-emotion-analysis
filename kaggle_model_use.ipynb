{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f90ee3c",
   "metadata": {},
   "source": [
    "### MalgrÃ© les apparences, c'est bien le dataset MELD qui a Ã©tÃ© utilisÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c13339fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbfc6e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ§ Fichier : 4.wav\n",
      "ðŸ”® Sentiment prÃ©dit : neutral\n",
      "ðŸ“Š ProbabilitÃ©s par sentiment :\n",
      "  negative: 0.3273\n",
      "  neutral: 0.5437\n",
      "  positive: 0.1290\n"
     ]
    }
   ],
   "source": [
    "#Test avec un seul fichier audio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Mettre le chemin du modÃ¨le ici\n",
    "model = joblib.load(\"kaggle_save/GaussianNB.joblib\")\n",
    "\n",
    "# Ordre important\n",
    "sentiment_labels = ['negative', 'neutral', 'positive']\n",
    "\n",
    "def extract_mfcc(filepath, n_mfcc=13):\n",
    "    y, sr = librosa.load(filepath, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfcc.T, axis=0)\n",
    "\n",
    "audio_file = \"sdataset/TEST/4.wav\"\n",
    "\n",
    "features = extract_mfcc(audio_file).reshape(1, -1)\n",
    "proba = model.predict_proba(features)[0]\n",
    "pred_sentiment = sentiment_labels[np.argmax(proba)]\n",
    "\n",
    "print(f\"\\nðŸŽ§ Fichier : {os.path.basename(audio_file)}\")\n",
    "print(f\"ðŸ”® Sentiment prÃ©dit : {pred_sentiment}\")\n",
    "print(\"ðŸ“Š ProbabilitÃ©s par sentiment :\")\n",
    "for label, p in zip(sentiment_labels, proba):\n",
    "    print(f\"  {label}: {p:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93896000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c96bf52dc546849c4edd8ab5fba556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m file_list:\n\u001b[0;32m     31\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_folder, filename)\n\u001b[1;32m---> 32\u001b[0m     features \u001b[38;5;241m=\u001b[39m extract_mfcc(path)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m     proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(features)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     34\u001b[0m     pred \u001b[38;5;241m=\u001b[39m sentiment_labels[np\u001b[38;5;241m.\u001b[39margmax(proba)]\n",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m, in \u001b[0;36mextract_mfcc\u001b[1;34m(filepath, n_mfcc)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_mfcc\u001b[39m(filepath, n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m):\n\u001b[0;32m     15\u001b[0m     y, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(filepath, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 16\u001b[0m     mfcc \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr, n_mfcc\u001b[38;5;241m=\u001b[39mn_mfcc)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(mfcc\u001b[38;5;241m.\u001b[39mT, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\feature\\spectral.py:1993\u001b[0m, in \u001b[0;36mmfcc\u001b[1;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, mel_norm, **kwargs)\u001b[0m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m \n\u001b[0;32m   1848\u001b[0m \u001b[38;5;124;03m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1989\u001b[0m \u001b[38;5;124;03m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     \u001b[38;5;66;03m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[1;32m-> 1993\u001b[0m     S \u001b[38;5;241m=\u001b[39m power_to_db(melspectrogram(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr, norm \u001b[38;5;241m=\u001b[39m mel_norm, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m   1995\u001b[0m fft \u001b[38;5;241m=\u001b[39m get_fftlib()\n\u001b[0;32m   1996\u001b[0m M: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m fft\u001b[38;5;241m.\u001b[39mdct(S, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mdct_type, norm\u001b[38;5;241m=\u001b[39mnorm)[\n\u001b[0;32m   1997\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :n_mfcc, :\n\u001b[0;32m   1998\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\feature\\spectral.py:2148\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[1;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[0;32m   2135\u001b[0m S, n_fft \u001b[38;5;241m=\u001b[39m _spectrogram(\n\u001b[0;32m   2136\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   2137\u001b[0m     S\u001b[38;5;241m=\u001b[39mS,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2144\u001b[0m     pad_mode\u001b[38;5;241m=\u001b[39mpad_mode,\n\u001b[0;32m   2145\u001b[0m )\n\u001b[0;32m   2147\u001b[0m \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[1;32m-> 2148\u001b[0m mel_basis \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mmel(sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39mn_fft, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2150\u001b[0m melspec: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...ft,mf->...mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, S, mel_basis, optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m melspec\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\filters.py:239\u001b[0m, in \u001b[0;36mmel\u001b[1;34m(sr, n_fft, n_mels, fmin, fmax, htk, norm, dtype)\u001b[0m\n\u001b[0;32m    236\u001b[0m     upper \u001b[38;5;241m=\u001b[39m ramps[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m/\u001b[39m fdiff[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# .. then intersect them with each other and zero\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     weights[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39mminimum(lower, upper))\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(norm, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslaney\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;66;03m# Slaney-style mel is scaled to be approx constant energy per channel\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test avec un dossier de fichiers audio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from rich.live import Live\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "# Chargement du modÃ¨le\n",
    "model = joblib.load(\"kaggle_save/GaussianNB.joblib\")\n",
    "sentiment_labels = ['negative', 'neutral', 'positive']\n",
    "\n",
    "def extract_mfcc(filepath, n_mfcc=13):\n",
    "    y, sr = librosa.load(filepath, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfcc.T, axis=0)\n",
    "\n",
    "test_folder = \"dataset_clean/test/audios\"\n",
    "file_list = sorted([f for f in os.listdir(test_folder) if f.lower().endswith(\".wav\")])\n",
    "\n",
    "table = Table(show_header=True, header_style=\"bold magenta\")\n",
    "table.add_column(\"Fichier\", justify=\"left\")\n",
    "table.add_column(\"PrÃ©dit\", justify=\"center\")\n",
    "table.add_column(\"Negative\", justify=\"right\")\n",
    "table.add_column(\"Neutral\", justify=\"right\")\n",
    "table.add_column(\"Positive\", justify=\"right\")\n",
    "\n",
    "with Live(table, refresh_per_second=4) as live:\n",
    "    for filename in file_list:\n",
    "        path = os.path.join(test_folder, filename)\n",
    "        features = extract_mfcc(path).reshape(1, -1)\n",
    "        proba = model.predict_proba(features)[0]\n",
    "        pred = sentiment_labels[np.argmax(proba)]\n",
    "\n",
    "        table.add_row(\n",
    "            filename,\n",
    "            pred,\n",
    "            f\"{proba[0]:.4f}\",\n",
    "            f\"{proba[1]:.4f}\",\n",
    "            f\"{proba[2]:.4f}\"\n",
    "        )\n",
    "        live.update(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90231e59",
   "metadata": {},
   "source": [
    "## En temps rÃ©el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a196ae17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrage du bruit ambiant...\n",
      "DÃ©marrage reconnaissance vocale et dÃ©tection sentiment...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecd85c815e14551888a4cf4f7fe1717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ArrÃªt en cours...\n",
      "Programme arrÃªtÃ©.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import time\n",
    "import numpy as np\n",
    "import joblib\n",
    "import librosa\n",
    "from rich.live import Live\n",
    "from rich.table import Table\n",
    "from rich.panel import Panel\n",
    "from rich.console import Group, Console\n",
    "\n",
    "model = joblib.load(\"kaggle_save/GaussianNB.joblib\")\n",
    "sentiment_labels = ['negative', 'neutral', 'positive']\n",
    "\n",
    "last_transcription = \"\"\n",
    "stop = False  # flag pour arrÃªter la boucle\n",
    "\n",
    "def extract_mfcc_from_audio_data(audio_data, sr=16000, n_mfcc=13):\n",
    "    mfcc = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfcc.T, axis=0)\n",
    "\n",
    "def callback(recognizer, audio):\n",
    "    global last_transcription\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio, language=\"fr-FR\")\n",
    "        last_transcription = text\n",
    "\n",
    "        audio_data_int16 = np.frombuffer(audio.get_raw_data(), dtype=np.int16)\n",
    "        audio_data = audio_data_int16.astype(np.float32) / 32768.0\n",
    "\n",
    "        features = extract_mfcc_from_audio_data(audio_data).reshape(1, -1)\n",
    "        proba = model.predict_proba(features)[0]\n",
    "        pred_sentiment = sentiment_labels[np.argmax(proba)]\n",
    "\n",
    "        timestamp = time.strftime(\"%H:%M:%S\")\n",
    "\n",
    "        table.add_row(timestamp, pred_sentiment, f\"{proba[0]:.4f}\", f\"{proba[1]:.4f}\", f\"{proba[2]:.4f}\")\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "        last_transcription = \"[Audio incompris]\"\n",
    "    except sr.RequestError as e:\n",
    "        last_transcription = f\"[Erreur service reconnaissance vocale: {e}]\"\n",
    "    except Exception as e:\n",
    "        last_transcription = f\"[Erreur: {e}]\"\n",
    "\n",
    "def main():\n",
    "    global table, stop\n",
    "\n",
    "    r = sr.Recognizer()\n",
    "    m = sr.Microphone()\n",
    "\n",
    "    table = Table(show_header=True, header_style=\"bold magenta\")\n",
    "    table.add_column(\"Timestamp\", justify=\"center\")\n",
    "    table.add_column(\"Sentiment prÃ©dit\", justify=\"center\")\n",
    "    table.add_column(\"Negative\", justify=\"right\")\n",
    "    table.add_column(\"Neutral\", justify=\"right\")\n",
    "    table.add_column(\"Positive\", justify=\"right\")\n",
    "\n",
    "    with m as source:\n",
    "        print(\"Calibrage du bruit ambiant...\")\n",
    "        r.adjust_for_ambient_noise(source, duration=2)\n",
    "\n",
    "    print(\"DÃ©marrage reconnaissance vocale et dÃ©tection sentiment...\")\n",
    "\n",
    "    stop_listening = r.listen_in_background(m, callback)\n",
    "\n",
    "    console = Console()\n",
    "\n",
    "    try:\n",
    "        with Live(console=console, refresh_per_second=4) as live:\n",
    "            while not stop:\n",
    "                panel = Panel(last_transcription or \"[Aucune transcription]\", title=\"Transcription\", style=\"cyan\")\n",
    "                group = Group(table, panel)\n",
    "                live.update(group)\n",
    "                time.sleep(0.1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nArrÃªt en cours...\")\n",
    "        stop_listening(wait_for_stop=True)\n",
    "        print(\"Programme arrÃªtÃ©.\")\n",
    "        stop = True  # Ã§a stoppe la boucle proprement\n",
    "\n",
    "# Lancer la fonction main()\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe61cbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.5\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c808d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
