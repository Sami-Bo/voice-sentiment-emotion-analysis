{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12753e7b",
   "metadata": {},
   "source": [
    "### Exemple d'utilisation du mod√®le xgboost avec dataset ravdess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03009b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "xgb_model = joblib.load(\"model_save/xgb_model.joblib\")\n",
    "\n",
    "# Labels (l'ordre est important)\n",
    "emotion_labels = ['neutral', 'calm', 'joy', 'sadness', 'anger', 'fear', 'disgust', 'surprise']\n",
    "\n",
    "# Fonction MFCC\n",
    "def extract_mfcc(filepath, n_mfcc=40):\n",
    "    y, sr = librosa.load(filepath, sr=None)\n",
    "    return np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc).T, axis=0)\n",
    "\n",
    "# Fichier audio\n",
    "audio_path = \"dataset_clean/test/audios/dia0_utt0.wav\"\n",
    "\n",
    "# Pr√©diction\n",
    "features = extract_mfcc(audio_path).reshape(1, -1)\n",
    "proba = xgb_model.predict_proba(features)[0]\n",
    "pred_emotion = emotion_labels[np.argmax(proba)]\n",
    "\n",
    "print(f\"\\nüéß Fichier : {audio_path}\")\n",
    "print(f\"üîÆ Emotion pr√©dite : {pred_emotion}\\n\")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"√âmotion\": emotion_labels,\n",
    "    \"Probabilit√©\": np.round(proba, 4)\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Probabilit√©s par √©motion :\\n\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd21c1cc",
   "metadata": {},
   "source": [
    "**Petite pr√©cision : il y a l'√©motion \"calm\" dans le dataset ravdess mais pas dans meld. \n",
    "Si c'est un probl√®me on peut par exemple la remplacer par \"neutral\" avec ce code :** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "xgb_model = joblib.load(\"model_save/xgb_model.joblib\")\n",
    "\n",
    "emotion_labels = ['neutral', 'calm', 'joy', 'sadness', 'anger', 'fear', 'disgust', 'surprise']\n",
    "\n",
    "def extract_mfcc(filepath, n_mfcc=40):\n",
    "    y, sr = librosa.load(filepath, sr=None)\n",
    "    return np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc).T, axis=0)\n",
    "\n",
    "audio_path = \"dataset_clean/test/audios/dia0_utt0.wav\"\n",
    "\n",
    "features = extract_mfcc(audio_path).reshape(1, -1)\n",
    "proba = xgb_model.predict_proba(features)[0]\n",
    "\n",
    "# Somme des probabilit√©s 'neutral' + 'calm'\n",
    "neutral_idx = emotion_labels.index('neutral')\n",
    "calm_idx = emotion_labels.index('calm')\n",
    "\n",
    "proba_merged = proba.copy()\n",
    "proba_merged[neutral_idx] += proba_merged[calm_idx]\n",
    "\n",
    "# On retire 'calm' du tableau pour √©viter doublons\n",
    "merged_labels = [e for e in emotion_labels if e != 'calm']\n",
    "merged_proba = np.delete(proba_merged, calm_idx)\n",
    "\n",
    "# Pr√©diction sur les probabilit√©s fusionn√©es\n",
    "pred_idx = np.argmax(merged_proba)\n",
    "pred_emotion = merged_labels[pred_idx]\n",
    "\n",
    "print(f\"\\nüéß Fichier : {audio_path}\")\n",
    "print(f\"üîÆ Emotion pr√©dite : {pred_emotion}\\n\")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"√âmotion\": merged_labels,\n",
    "    \"Probabilit√©\": np.round(merged_proba, 4)\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Probabilit√©s par √©motion (calm fusionn√© avec neutral) :\\n\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3377a33",
   "metadata": {},
   "source": [
    "### En temps r√©el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da621f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import time\n",
    "import numpy as np\n",
    "import joblib\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "# Charger mod√®le XGBoost\n",
    "xgb_model = joblib.load(\"model_save/xgb_model.joblib\")\n",
    "\n",
    "# √âtiquettes √©motions (ordre important)\n",
    "emotion_labels = ['neutral', 'calm', 'joy', 'sadness', 'anger', 'fear', 'disgust', 'surprise']\n",
    "\n",
    "# Fonction extraction MFCC moyenne depuis buffer audio raw\n",
    "def extract_mfcc_from_audio_data(audio_data, sr=16000, n_mfcc=40):\n",
    "    # audio_data est un array numpy float32 de la forme (samples,)\n",
    "    mfcc = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc_mean = np.mean(mfcc.T, axis=0)\n",
    "    return mfcc_mean\n",
    "\n",
    "# Callback pour le recognizer (avec transcription)\n",
    "def callback(recognizer, audio):\n",
    "    try:\n",
    "        # Transcription en fran√ßais\n",
    "        text = recognizer.recognize_google(audio, language=\"fr-FR\")\n",
    "        print(f\"\\nüó£Ô∏è Transcription : {text}\")\n",
    "\n",
    "        # R√©cup√©rer le buffer audio raw (int16)\n",
    "        audio_data_int16 = np.frombuffer(audio.get_raw_data(), dtype=np.int16)\n",
    "        # Convertir en float32 entre -1 et 1\n",
    "        audio_data = audio_data_int16.astype(np.float32) / 32768.0\n",
    "        \n",
    "        # Extraire features MFCC\n",
    "        features = extract_mfcc_from_audio_data(audio_data).reshape(1, -1)\n",
    "        \n",
    "        # Pr√©dire √©motion\n",
    "        proba = xgb_model.predict_proba(features)[0]\n",
    "        pred_emotion = emotion_labels[np.argmax(proba)]\n",
    "        \n",
    "        # Afficher r√©sultats √©motion\n",
    "        print(f\"üîÆ Emotion pr√©dite : {pred_emotion}\")\n",
    "        df = pd.DataFrame({\n",
    "            \"√âmotion\": emotion_labels,\n",
    "            \"Probabilit√©\": np.round(proba, 4)\n",
    "        })\n",
    "        print(df.to_string(index=False))\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"üõë Audio incompris.\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"‚ùå Erreur service reconnaissance vocale : {e}\")\n",
    "    except Exception as e:\n",
    "        print(\"Erreur lors de l'extraction/prediction :\", e)\n",
    "\n",
    "# Initialisation recognizer et micro\n",
    "r = sr.Recognizer()\n",
    "m = sr.Microphone()\n",
    "\n",
    "# Ajuster pour bruit ambiant\n",
    "with m as source:\n",
    "    print(\"Calibrage du bruit ambiant...\")\n",
    "    r.adjust_for_ambient_noise(source, duration=2)\n",
    "print(\"D√©marrage de la reconnaissance vocale et d√©tection d'√©motion...\")\n",
    "\n",
    "# Lancement de l'√©coute en arri√®re-plan\n",
    "stop_listening = r.listen_in_background(m, callback)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(0.1)  # garder le script actif\n",
    "except KeyboardInterrupt:\n",
    "    stop_listening(wait_for_stop=False)\n",
    "    print(\"Programme arr√™t√©.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f9a677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
